{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/conda/pkgs')\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/4262b1bf4bf1ffb403c0eb7a42ad5906_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/4506eccf78279d93d0e8a34c035e91c5_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/6bda807e3967eae797c7b1b9eeaee8db_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/c2a47d89d1d34e789fdf782557bb7194_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/c6c5514ada15b890fb27d1e36371554c_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/d964a294c2d0fef56a434c021026281e_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/e1c932db5cd4271709e54d8028824bc9_/lib/python3.12/site-packages\")\n",
    "import gzip, json\n",
    "from Bio import SeqIO\n",
    "import scipy.sparse as sp\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "fasta_gz_file = '/home/miaocj/docker_dir/kNN-overlap-finder/data/regional_reads/Ecoli/all/ONT/reads.fasta.gz'\n",
    "paf_gz_file = '/home/miaocj/docker_dir/kNN-overlap-finder/data/regional_reads/Ecoli/all/ONT/alignment.paf.gz'\n",
    "with gzip.open(paf_gz_file, \"rt\") as file:\n",
    "    max_values = {}  \n",
    "    for row in file:  \n",
    "        columns = row.strip().split('\\t') \n",
    "        query_id = columns[0]  \n",
    "        match_bases = int(columns[9]) \n",
    "        max_values[query_id] = columns \n",
    "        if query_id in max_values:  \n",
    "            if match_bases > int(max_values[query_id][9]):  \n",
    "                max_values[match_bases] = columns\n",
    "        else:  \n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/conda/pkgs')\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/4262b1bf4bf1ffb403c0eb7a42ad5906_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/4506eccf78279d93d0e8a34c035e91c5_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/6bda807e3967eae797c7b1b9eeaee8db_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/c2a47d89d1d34e789fdf782557bb7194_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/c6c5514ada15b890fb27d1e36371554c_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/d964a294c2d0fef56a434c021026281e_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/e1c932db5cd4271709e54d8028824bc9_/lib/python3.12/site-packages\")\n",
    "import pickle, os, gzip, json, sys, itertools\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "from dataclasses import dataclass, field\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysam\n",
    "import scipy as sp\n",
    "import seaborn\n",
    "import sharedmem\n",
    "import pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/miaocj/docker_dir/kNN-overlap-finder/scripts/../lib\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"scripts\")\n",
    "sys.path.append(\"../../scripts\")\n",
    "from data_io import is_fwd_id, get_fwd_id, get_sibling_id\n",
    "from graph import OverlapGraph, GenomicInterval, get_overlap_statistics, remove_false_edges\n",
    "from truth import get_overlaps\n",
    "from evaluate import NearestNeighborsConfig, mp_compute_nearest_neighbors\n",
    "from plots import plot_read_graph, mp_plot_read_graphs, get_graphviz_layout, get_umap_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "from memory_profiler import profile\n",
    "%load_ext memory_profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 5395.32 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit x = 10+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9493518828919433\n",
      "0.9829031176667784\n"
     ]
    }
   ],
   "source": [
    "MAX_SAMPLE_SIZE = int(1e9)\n",
    "COVERAGE_DEPTH = 20\n",
    "max_n_neighbors = 20\n",
    "with gzip.open(fasta_gz_file, \"rt\") as handle:\n",
    "    flag = 0\n",
    "    seq_num = 0\n",
    "    aligned_num = 0\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        seq_num += 1\n",
    "        if record.id in max_values.keys():\n",
    "            aligned_num+=1\n",
    "            columns = max_values[record.id]\n",
    "            if int(columns[9])/int(columns[1]) > 0.5:\n",
    "                flag += 1\n",
    "    print(flag/seq_num)\n",
    "    print(aligned_num/seq_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_path = \"/home/miaocj/docker_dir/kNN-overlap-finder/data/feature_matrix/CHM13/HLA/pbsim_ONT_93_30k/kmer_k16/feature_matrix.npz\"\n",
    "tsv_path = \"/home/miaocj/docker_dir/kNN-overlap-finder/data/feature_matrix/CHM13/HLA/pbsim_ONT_93_30k//kmer_k16/metadata.tsv.gz\"\n",
    "json_path = \"/home/miaocj/docker_dir/kNN-overlap-finder/data/feature_matrix/CHM13/HLA/pbsim_ONT_93_30k/kmer_k16/read_features.json.gz\"\n",
    "\n",
    "nbr_path = '/home/miaocj/docker_dir/kNN-overlap-finder/data/evaluation/Ecoli/all/ONT/kmer_k16/HNSW_Euclidean_scBiMap_500d_TF-IDF_nbr_matrix.npz'\n",
    "time_path = '/home/miaocj/docker_dir/kNN-overlap-finder/data/evaluation/Ecoli/all/ONT/kmer_k16/HNSW_Euclidean_scBiMap_500d_TF-IDF_time_usage.json'\n",
    "meta_df = pd.read_table(tsv_path).iloc[:MAX_SAMPLE_SIZE, :].reset_index()\n",
    "read_indices = {read_name: read_id for read_id, read_name in meta_df['read_name'].items()}\n",
    "feature_matrix = sp.sparse.load_npz(npz_path)[meta_df.index, :]\n",
    "\n",
    "with gzip.open(json_path, \"rt\") as f:\n",
    "    read_features = json.load(f)\n",
    "    read_features = {i: read_features[i] for i in meta_df.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7448, 1265400)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299897765\n",
      "2378963497\n",
      "44873935\n",
      "2670060064\n",
      "25935175\n",
      "920060685\n",
      "1586326711\n",
      "1550303102\n",
      "278283145\n",
      "1103905279\n",
      "2497529993\n",
      "993549511\n",
      "3538826777\n",
      "827898949\n",
      "1744767203\n",
      "1454149367\n",
      "347405931\n",
      "293704892\n",
      "739522939\n",
      "2787976300\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import collections  \n",
    "from typing import Mapping  \n",
    "from numba import jit\n",
    "\n",
    "\n",
    "def _hash(kmer_index: str, seed: int) -> int:\n",
    "    hash_value = mmh3.hash(kmer_index, seed=seed)\n",
    "    binary_string = format(hash_value & 0xFFFFFFFF, '032b')\n",
    "    hash_list = [int(x) for x in binary_string]\n",
    "    hash_list1 = np.array(hash_list)\n",
    "    return hash_list1\n",
    "\n",
    "def _get_simhash(  \n",
    "    read_features: list,  \n",
    "    feature_matrix: list,   \n",
    "    repeat: int,   \n",
    "    seed: int) -> Mapping[int,list]:  \n",
    "      \n",
    "    rng = np.random.default_rng(seed)  \n",
    "    hash_seeds = rng.integers(low=0, high=2**32 - 1, size=repeat, dtype=np.uint64)  \n",
    "  \n",
    "    repeat_all_read_hash = []  \n",
    "    for s in hash_seeds:  \n",
    "        print(s)\n",
    "        kmer_hash_indice = {}  \n",
    "        for kmer_index in range(feature_matrix.shape[1]):  \n",
    "            kmer_index_str = str(kmer_index)  \n",
    "            hash_list = _hash(kmer_index_str, seed=s)  \n",
    "            kmer_hash_indice[kmer_index] = hash_list  \n",
    "  \n",
    "        all_read_simhash = []  \n",
    "        for features in read_features.values():  \n",
    "            feature_count = dict(collections.Counter(features))  \n",
    "            one_read_hash = []  \n",
    "            for indice, count in feature_count.items():  \n",
    "                hash_list = kmer_hash_indice[indice]\n",
    "                hash_list = np.where(hash_list == 0, -1, hash_list) \n",
    "                weighted_hash_list = hash_list * count  \n",
    "                one_read_hash.append(weighted_hash_list)  \n",
    "            one_read_hash_array = np.array(one_read_hash)  \n",
    "            hash_sum = np.sum(one_read_hash_array, axis=0)   \n",
    "            simhash_value = np.where(hash_sum > 0, 1, 0)  \n",
    "            all_read_simhash.append(simhash_value)  \n",
    "  \n",
    "        repeat_all_read_hash.append(all_read_simhash)  \n",
    "  \n",
    "    concat_simhash = np.concatenate(repeat_all_read_hash, axis=1)  \n",
    "  \n",
    "    return concat_simhash \n",
    "\n",
    "def hamming_distance(x, y):  \n",
    "    return np.count_nonzero(x != y)\n",
    "nbrs = NearestNeighbors(n_neighbors=21, algorithm='auto', metric=hamming_distance)\n",
    "nbrs.fit(concat_simhash)  \n",
    "indices = nbrs.kneighbors(concat_simhash,return_distance=False)\n",
    "nbr_indices = indices[:, 1:]\n",
    "    \n",
    "concat_simhash = _get_simhash(read_features,feature_matrix,repeat = 20, seed = 4829)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5056349019871106"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.count_nonzero(concat_simhash == 0)/concat_simhash.size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors  \n",
    "from scipy.spatial.distance import hamming  \n",
    "  \n",
    "def hamming_distance(x, y):  \n",
    "    return np.count_nonzero(x != y)\n",
    "nbrs = NearestNeighbors(n_neighbors=21, algorithm='auto', metric=hamming_distance)\n",
    "nbrs.fit(concat_simhash)  \n",
    "indices = nbrs.kneighbors(concat_simhash,return_distance=False)\n",
    "nbr_indices = indices[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_table(tsv_path).iloc[:MAX_SAMPLE_SIZE, :].reset_index()\n",
    "read_indices = {read_name: read_id for read_id, read_name in meta_df['read_name'].items()}\n",
    "feature_matrix = sp.sparse.load_npz(npz_path)[meta_df.index, :]\n",
    "\n",
    "with gzip.open(json_path, \"rt\") as f:\n",
    "    read_features = json.load(f)\n",
    "    read_features = {i: read_features[i] for i in meta_df.index}\n",
    "\n",
    "feature_weights = {i: 1 for i in range(feature_matrix.shape[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_ids = np.array(list(read_features))\n",
    "graphs = collections.defaultdict(dict)\n",
    "k_values = np.arange(2, max_n_neighbors + 1)\n",
    "\n",
    "for k in k_values:\n",
    "    graph = OverlapGraph.from_neighbor_indices(\n",
    "        neighbor_indices=nbr_indices,\n",
    "        n_neighbors=k,\n",
    "        read_ids=read_ids,\n",
    "        require_mutual_neighbors=False,\n",
    "    )\n",
    "    graphs[k] = graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7448, 150966, 14394, 2)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_read_intervals(meta_df):\n",
    "    read_intervals = {\n",
    "        i: [GenomicInterval(strand, start, end)]\n",
    "        for i, strand, start, end in zip(\n",
    "            meta_df.index,\n",
    "            meta_df[\"reference_strand\"],\n",
    "            meta_df[\"reference_start\"],\n",
    "            meta_df[\"reference_end\"],\n",
    "        )\n",
    "    }\n",
    "    return read_intervals\n",
    "\n",
    "read_intervals = get_read_intervals(meta_df)\n",
    "\n",
    "reference_graph = OverlapGraph.from_intervals(read_intervals)\n",
    "nr_edges = set((node_1, node_2) for node_1, node_2, data in reference_graph.edges(data=True) if not data['redundant'])\n",
    "connected_component_count = len(list(nx.connected_components(reference_graph)))\n",
    "len(reference_graph.nodes), len(reference_graph.edges), len(nr_edges), connected_component_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rows = []\n",
    "\n",
    "for k in k_values:\n",
    "    graph = graphs[k]\n",
    "    graph_stats = get_overlap_statistics(query_graph=graph, reference_graph=reference_graph)\n",
    "    stats = { \"n_neighbors\": k}\n",
    "    df_rows.append(stats)\n",
    "df = pd.DataFrame(df_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.9025594824591873,\n",
       " 'nr_precision': 0.14440778047933311,\n",
       " 'recall': 0.5507928937641589,\n",
       " 'nr_recall': 0.9242740030568293,\n",
       " 'singleton_count': 22,\n",
       " 'singleton_fraction': 0.002953813104189044,\n",
       " 'N50': 3717}"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_rl:container1.0",
   "language": "python",
   "name": "deep_rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
