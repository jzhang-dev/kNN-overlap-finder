{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/conda/pkgs')\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/4262b1bf4bf1ffb403c0eb7a42ad5906_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/4506eccf78279d93d0e8a34c035e91c5_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/6bda807e3967eae797c7b1b9eeaee8db_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/c2a47d89d1d34e789fdf782557bb7194_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/c6c5514ada15b890fb27d1e36371554c_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/d964a294c2d0fef56a434c021026281e_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/e1c932db5cd4271709e54d8028824bc9_/lib/python3.12/site-packages\")\n",
    "import gzip, json\n",
    "from Bio import SeqIO\n",
    "import scipy.sparse as sp\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "fasta_gz_file = '/home/miaocj/docker_dir/kNN-overlap-finder/data/regional_reads/Ecoli/all/ONT/reads.fasta.gz'\n",
    "paf_gz_file = '/home/miaocj/docker_dir/kNN-overlap-finder/data/regional_reads/Ecoli/all/ONT/alignment.paf.gz'\n",
    "with gzip.open(paf_gz_file, \"rt\") as file:\n",
    "    max_values = {}  \n",
    "    for row in file:  \n",
    "        columns = row.strip().split('\\t') \n",
    "        query_id = columns[0]  \n",
    "        match_bases = int(columns[9]) \n",
    "        max_values[query_id] = columns \n",
    "        if query_id in max_values:  \n",
    "            if match_bases > int(max_values[query_id][9]):  \n",
    "                max_values[match_bases] = columns\n",
    "        else:  \n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle, os, gzip, json, sys, itertools\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "from dataclasses import dataclass, field\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from typing import Mapping  \n",
    "import mmh3\n",
    "from itertools import chain  \n",
    "import sharedmem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/miaocj/docker_dir/kNN-overlap-finder/scripts/../lib\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"scripts\")\n",
    "sys.path.append(\"../../scripts\")\n",
    "from graph import OverlapGraph, GenomicInterval, get_overlap_statistics, remove_false_edges\n",
    "from nearest_neighbors import HNSW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import collections  \n",
    "from typing import Mapping  \n",
    "from sklearn.neighbors import NearestNeighbors  \n",
    "from scipy.spatial.distance import hamming  \n",
    "import mmh3  \n",
    "import random\n",
    "import secrets\n",
    "max_n_neighbors = 20\n",
    "MAX_SAMPLE_SIZE = int(1e9)\n",
    "k_values = np.arange(2, max_n_neighbors + 1)\n",
    "def hamming_distance(x, y):  \n",
    "    return np.count_nonzero(x != y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_path = \"/home/miaocj/docker_dir/kNN-overlap-finder/data/feature_matrix/human/HLA/ONT_R9/kmer_k16/feature_matrix.npz\"\n",
    "tsv_path = \"/home/miaocj/docker_dir/kNN-overlap-finder/data/feature_matrix/human/HLA/ONT_R9/kmer_k16/metadata.tsv.gz\"\n",
    "json_path = \"/home/miaocj/docker_dir/kNN-overlap-finder/data/feature_matrix/human/HLA/ONT_R9/kmer_k16/read_features.json.gz\"\n",
    "\n",
    "meta_df = pd.read_table(tsv_path).iloc[:MAX_SAMPLE_SIZE, :].reset_index()\n",
    "read_indices = {read_name: read_id for read_id, read_name in meta_df['read_name'].items()}\n",
    "feature_matrix = sp.sparse.load_npz(npz_path)[meta_df.index, :]\n",
    "\n",
    "with gzip.open(json_path, \"rt\") as f:\n",
    "    read_features = json.load(f)\n",
    "    read_features = {i: read_features[i] for i in meta_df.index}\n",
    "\n",
    "read_ids = np.array(list(read_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12926, 324674, 25276, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_read_intervals(meta_df):\n",
    "    read_intervals = {\n",
    "        i: [GenomicInterval(strand, start, end)]\n",
    "        for i, strand, start, end in zip(\n",
    "            meta_df.index,\n",
    "            meta_df[\"reference_strand\"],\n",
    "            meta_df[\"reference_start\"],\n",
    "            meta_df[\"reference_end\"],\n",
    "        )\n",
    "    }\n",
    "    return read_intervals\n",
    "\n",
    "read_intervals = get_read_intervals(meta_df)\n",
    "\n",
    "reference_graph = OverlapGraph.from_intervals(read_intervals)\n",
    "nr_edges = set((node_1, node_2) for node_1, node_2, data in reference_graph.edges(data=True) if not data['redundant'])\n",
    "connected_component_count = len(list(nx.connected_components(reference_graph)))\n",
    "len(reference_graph.nodes), len(reference_graph.edges), len(nr_edges), connected_component_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##法一：用secret函数 kmer_index 直接作为种子\n",
    "def _hash(kmer_index: int) -> np.ndarray:\n",
    "    random.seed(kmer_index)\n",
    "    random_number = secrets.token_bytes(400)\n",
    "    random_integer = int.from_bytes(random_number, byteorder='big')  \n",
    "    binary_array = format(random_integer, '03200b')\n",
    "    hash_array = list(binary_array)\n",
    "    return hash_array\n",
    "def _get_table(\n",
    "    kmer_num: list) -> Mapping[int,list]:\n",
    "    hash_table = np.empty((kmer_num,3200),dtype=np.int8) \n",
    "    for kmer_index in range(kmer_num):\n",
    "        hash_array = _hash(kmer_index)\n",
    "        hash_table[kmer_index,:]=hash_array\n",
    "    hash_table = np.where(hash_table == 0, -1, 1) \n",
    "    return hash_table\n",
    "hash_table = _get_table(feature_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "simhash = feature_matrix@hash_table\n",
    "reads_simhash_array = np.where(simhash > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pynear\n",
      "  Downloading pynear-0.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/3172702e82c9c1d9450fdd20452651b9_/lib/python3.12/site-packages (from pynear) (1.26.4)\n",
      "Downloading pynear-0.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (332 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.8/332.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: pynear\n",
      "Successfully installed pynear-0.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pynear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 1, 1],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [1, 0, 0, ..., 1, 1, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 0, 1],\n",
       "       [0, 1, 1, ..., 1, 1, 1],\n",
       "       [0, 0, 1, ..., 1, 0, 1]], dtype=int8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reads_simhash_array.astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynear\n",
    "vptree = pynear.VPTreeBinaryIndex()\n",
    "vptree.set(reads_simhash_array.astype(np.uint8))\n",
    "vptree_indices, vptree_distances = vptree.searchKNN(reads_simhash_array.astype(np.uint8), 21)\n",
    "vp_nbr= np.array(vptree_indices)[:,:-1][:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11900,  1764,  5988, ..., 12076,  6839,  1711],\n",
       "       [11901,  5989,  5504, ...,  8245,  3398,  3230],\n",
       "       [  598, 12019,  2068, ...,  9687,  4399,  6843],\n",
       "       ...,\n",
       "       [ 8636,  9267,  8123, ...,  4184, 12577,  5141],\n",
       "       [ 1890,  3291, 11969, ...,  9363, 11337,  3040],\n",
       "       [ 1891,  3290, 11968, ...,  9362, 11336,  3041]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vp_nbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= nbr_indices == vp_nbr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13138"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test==False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245382"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rows = []\n",
    "for k in k_values:\n",
    "    graph = OverlapGraph.from_neighbor_indices(\n",
    "        neighbor_indices=vp_nbr,\n",
    "        n_neighbors=k,\n",
    "        read_ids=read_ids,\n",
    "        require_mutual_neighbors=False,\n",
    "    )\n",
    "    graph_stats = get_overlap_statistics(query_graph=graph, reference_graph=reference_graph)\n",
    "    stats = { \"n_neighbors\": k}\n",
    "    stats = {\"description\":'method2', \"n_neighbors\": k, \"repeat_time\": 1,\n",
    "                **graph_stats}\n",
    "    df_rows.append(stats)\n",
    "df = pd.DataFrame(df_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>repeat_time</th>\n",
       "      <th>precision</th>\n",
       "      <th>nr_precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>nr_recall</th>\n",
       "      <th>singleton_count</th>\n",
       "      <th>singleton_fraction</th>\n",
       "      <th>N50</th>\n",
       "      <th>component_sizes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>method2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991793</td>\n",
       "      <td>0.329497</td>\n",
       "      <td>0.061040</td>\n",
       "      <td>0.260484</td>\n",
       "      <td>123</td>\n",
       "      <td>0.009516</td>\n",
       "      <td>207</td>\n",
       "      <td>[777, 567, 551, 433, 423, 407, 345, 325, 310, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>method2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990384</td>\n",
       "      <td>0.289733</td>\n",
       "      <td>0.089459</td>\n",
       "      <td>0.336169</td>\n",
       "      <td>77</td>\n",
       "      <td>0.005957</td>\n",
       "      <td>1255</td>\n",
       "      <td>[2791, 2093, 1286, 1255, 1206, 1201, 1163, 115...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>method2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989292</td>\n",
       "      <td>0.262276</td>\n",
       "      <td>0.117524</td>\n",
       "      <td>0.400222</td>\n",
       "      <td>58</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>3954</td>\n",
       "      <td>[5162, 3954, 1289, 1286, 1206, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>method2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988413</td>\n",
       "      <td>0.241740</td>\n",
       "      <td>0.145025</td>\n",
       "      <td>0.455610</td>\n",
       "      <td>50</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>3955</td>\n",
       "      <td>[6450, 3955, 2496, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>method2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987297</td>\n",
       "      <td>0.225527</td>\n",
       "      <td>0.171874</td>\n",
       "      <td>0.504312</td>\n",
       "      <td>48</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>6451</td>\n",
       "      <td>[6453, 6451, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>method2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986052</td>\n",
       "      <td>0.211260</td>\n",
       "      <td>0.198575</td>\n",
       "      <td>0.546487</td>\n",
       "      <td>43</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>6452</td>\n",
       "      <td>[6455, 6452, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>method2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984766</td>\n",
       "      <td>0.199379</td>\n",
       "      <td>0.224782</td>\n",
       "      <td>0.584586</td>\n",
       "      <td>42</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>6453</td>\n",
       "      <td>[6455, 6453, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>method2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983300</td>\n",
       "      <td>0.189789</td>\n",
       "      <td>0.250630</td>\n",
       "      <td>0.621380</td>\n",
       "      <td>39</td>\n",
       "      <td>0.003017</td>\n",
       "      <td>6453</td>\n",
       "      <td>[6455, 6453, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>method2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.981885</td>\n",
       "      <td>0.180797</td>\n",
       "      <td>0.276299</td>\n",
       "      <td>0.653505</td>\n",
       "      <td>37</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>6453</td>\n",
       "      <td>[6456, 6453, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>method2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980635</td>\n",
       "      <td>0.173274</td>\n",
       "      <td>0.301333</td>\n",
       "      <td>0.683929</td>\n",
       "      <td>36</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>6453</td>\n",
       "      <td>[6456, 6453, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>method2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979195</td>\n",
       "      <td>0.166696</td>\n",
       "      <td>0.326315</td>\n",
       "      <td>0.713562</td>\n",
       "      <td>35</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>6454</td>\n",
       "      <td>[6456, 6454, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>method2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977770</td>\n",
       "      <td>0.160382</td>\n",
       "      <td>0.350872</td>\n",
       "      <td>0.739278</td>\n",
       "      <td>34</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>6454</td>\n",
       "      <td>[6457, 6454, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>method2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975900</td>\n",
       "      <td>0.154812</td>\n",
       "      <td>0.374665</td>\n",
       "      <td>0.763451</td>\n",
       "      <td>33</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>6454</td>\n",
       "      <td>[6459, 6454, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>method2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.973923</td>\n",
       "      <td>0.149385</td>\n",
       "      <td>0.398474</td>\n",
       "      <td>0.785093</td>\n",
       "      <td>33</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>6454</td>\n",
       "      <td>[6459, 6454, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>method2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971860</td>\n",
       "      <td>0.144662</td>\n",
       "      <td>0.421558</td>\n",
       "      <td>0.806022</td>\n",
       "      <td>32</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>6455</td>\n",
       "      <td>[6459, 6455, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>method2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969544</td>\n",
       "      <td>0.140307</td>\n",
       "      <td>0.444270</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>30</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>6456</td>\n",
       "      <td>[6460, 6456, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>method2</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966938</td>\n",
       "      <td>0.136108</td>\n",
       "      <td>0.466699</td>\n",
       "      <td>0.843844</td>\n",
       "      <td>29</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>6456</td>\n",
       "      <td>[6460, 6456, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>method2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.963938</td>\n",
       "      <td>0.132245</td>\n",
       "      <td>0.488296</td>\n",
       "      <td>0.860500</td>\n",
       "      <td>29</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>6456</td>\n",
       "      <td>[6460, 6456, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>method2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960687</td>\n",
       "      <td>0.128371</td>\n",
       "      <td>0.509400</td>\n",
       "      <td>0.874347</td>\n",
       "      <td>29</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>6456</td>\n",
       "      <td>[6460, 6456, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description  n_neighbors  repeat_time  precision  nr_precision    recall  \\\n",
       "0      method2            2            1   0.991793      0.329497  0.061040   \n",
       "1      method2            3            1   0.990384      0.289733  0.089459   \n",
       "2      method2            4            1   0.989292      0.262276  0.117524   \n",
       "3      method2            5            1   0.988413      0.241740  0.145025   \n",
       "4      method2            6            1   0.987297      0.225527  0.171874   \n",
       "5      method2            7            1   0.986052      0.211260  0.198575   \n",
       "6      method2            8            1   0.984766      0.199379  0.224782   \n",
       "7      method2            9            1   0.983300      0.189789  0.250630   \n",
       "8      method2           10            1   0.981885      0.180797  0.276299   \n",
       "9      method2           11            1   0.980635      0.173274  0.301333   \n",
       "10     method2           12            1   0.979195      0.166696  0.326315   \n",
       "11     method2           13            1   0.977770      0.160382  0.350872   \n",
       "12     method2           14            1   0.975900      0.154812  0.374665   \n",
       "13     method2           15            1   0.973923      0.149385  0.398474   \n",
       "14     method2           16            1   0.971860      0.144662  0.421558   \n",
       "15     method2           17            1   0.969544      0.140307  0.444270   \n",
       "16     method2           18            1   0.966938      0.136108  0.466699   \n",
       "17     method2           19            1   0.963938      0.132245  0.488296   \n",
       "18     method2           20            1   0.960687      0.128371  0.509400   \n",
       "\n",
       "    nr_recall  singleton_count  singleton_fraction   N50  \\\n",
       "0    0.260484              123            0.009516   207   \n",
       "1    0.336169               77            0.005957  1255   \n",
       "2    0.400222               58            0.004487  3954   \n",
       "3    0.455610               50            0.003868  3955   \n",
       "4    0.504312               48            0.003713  6451   \n",
       "5    0.546487               43            0.003327  6452   \n",
       "6    0.584586               42            0.003249  6453   \n",
       "7    0.621380               39            0.003017  6453   \n",
       "8    0.653505               37            0.002862  6453   \n",
       "9    0.683929               36            0.002785  6453   \n",
       "10   0.713562               35            0.002708  6454   \n",
       "11   0.739278               34            0.002630  6454   \n",
       "12   0.763451               33            0.002553  6454   \n",
       "13   0.785093               33            0.002553  6454   \n",
       "14   0.806022               32            0.002476  6455   \n",
       "15   0.825843               30            0.002321  6456   \n",
       "16   0.843844               29            0.002244  6456   \n",
       "17   0.860500               29            0.002244  6456   \n",
       "18   0.874347               29            0.002244  6456   \n",
       "\n",
       "                                      component_sizes  \n",
       "0   [777, 567, 551, 433, 423, 407, 345, 325, 310, ...  \n",
       "1   [2791, 2093, 1286, 1255, 1206, 1201, 1163, 115...  \n",
       "2   [5162, 3954, 1289, 1286, 1206, 1, 1, 1, 1, 1, ...  \n",
       "3   [6450, 3955, 2496, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4   [6453, 6451, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "5   [6455, 6452, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "6   [6455, 6453, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "7   [6455, 6453, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "8   [6456, 6453, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "9   [6456, 6453, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "10  [6456, 6454, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "11  [6457, 6454, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "12  [6459, 6454, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "13  [6459, 6454, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "14   [6459, 6455, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "15         [6460, 6456, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "16         [6460, 6456, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "17         [6460, 6456, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "18         [6460, 6456, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=42)\n",
    "\n",
    "dimension = 32 # 32 bytes are 256 bit dimensional vectos\n",
    "num_points = 2021\n",
    "data = np.random.normal(scale=255, loc=0, size=(num_points, dimension)).astype(dtype=np.uint8)\n",
    "\n",
    "num_queries = 8\n",
    "queries = np.random.normal(scale=255, loc=0, size=(num_queries, dimension)).astype(dtype=np.uint8)\n",
    "\n",
    "vptree = pynear.BKTreeBinaryIndex()\n",
    "vptree.set(data)\n",
    "\n",
    "# To search using maximum threshold use dimension * 8 (the maximum distance) or set any other threshold\n",
    "indices, distances, keys = vptree.find_threshold(data, dimension * 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[1] == indices[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=21, algorithm='auto', metric=hamming_distance)\n",
    "nbrs.fit(reads_simhash_array)  \n",
    "indices = nbrs.kneighbors(reads_simhash_array,return_distance=False)\n",
    "nbr_indices = indices[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rows = []\n",
    "for k in k_values:\n",
    "    graph = OverlapGraph.from_neighbor_indices(\n",
    "        neighbor_indices=nbr_indices,\n",
    "        n_neighbors=k,\n",
    "        read_ids=read_ids,\n",
    "        require_mutual_neighbors=False,\n",
    "    )\n",
    "    graph_stats = get_overlap_statistics(query_graph=graph, reference_graph=reference_graph)\n",
    "    stats = { \"n_neighbors\": k}\n",
    "    stats = {\"description\":'method2', \"n_neighbors\": k, \"repeat_time\": 1,\n",
    "                **graph_stats}\n",
    "    df_rows.append(stats)\n",
    "df = pd.DataFrame(df_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11900,  1764,  5988, ..., 12076,  6839,  1711],\n",
       "       [11901,  5989,  5504, ...,  8245,  3398,  3230],\n",
       "       [  598, 12019,  2068, ...,  5981,  4399,  6843],\n",
       "       ...,\n",
       "       [ 8636,  9267,  8123, ...,  4184, 12577,  5141],\n",
       "       [ 1890,  3291, 11969, ...,  9363, 11337,  3040],\n",
       "       [ 1891,  3290, 11968, ...,  9362, 11336,  3041]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbr_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>repeat_time</th>\n",
       "      <th>precision</th>\n",
       "      <th>nr_precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>nr_recall</th>\n",
       "      <th>singleton_count</th>\n",
       "      <th>singleton_fraction</th>\n",
       "      <th>N50</th>\n",
       "      <th>component_sizes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>method2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991741</td>\n",
       "      <td>0.329212</td>\n",
       "      <td>0.061024</td>\n",
       "      <td>0.260207</td>\n",
       "      <td>124</td>\n",
       "      <td>0.009593</td>\n",
       "      <td>207</td>\n",
       "      <td>[777, 567, 551, 433, 423, 407, 345, 325, 310, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>method2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990384</td>\n",
       "      <td>0.289709</td>\n",
       "      <td>0.089456</td>\n",
       "      <td>0.336129</td>\n",
       "      <td>78</td>\n",
       "      <td>0.006034</td>\n",
       "      <td>1255</td>\n",
       "      <td>[2791, 2093, 1285, 1255, 1206, 1201, 1163, 115...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>method2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.989292</td>\n",
       "      <td>0.262620</td>\n",
       "      <td>0.117521</td>\n",
       "      <td>0.400736</td>\n",
       "      <td>59</td>\n",
       "      <td>0.004564</td>\n",
       "      <td>3954</td>\n",
       "      <td>[5162, 3954, 1289, 1286, 1206, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>method2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.988453</td>\n",
       "      <td>0.241728</td>\n",
       "      <td>0.145013</td>\n",
       "      <td>0.455531</td>\n",
       "      <td>50</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>3955</td>\n",
       "      <td>[6450, 3955, 2496, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>method2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987347</td>\n",
       "      <td>0.225588</td>\n",
       "      <td>0.171849</td>\n",
       "      <td>0.504352</td>\n",
       "      <td>48</td>\n",
       "      <td>0.003713</td>\n",
       "      <td>6451</td>\n",
       "      <td>[6453, 6451, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>method2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.986080</td>\n",
       "      <td>0.211258</td>\n",
       "      <td>0.198553</td>\n",
       "      <td>0.546408</td>\n",
       "      <td>43</td>\n",
       "      <td>0.003327</td>\n",
       "      <td>6452</td>\n",
       "      <td>[6455, 6452, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>method2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984737</td>\n",
       "      <td>0.199347</td>\n",
       "      <td>0.224752</td>\n",
       "      <td>0.584428</td>\n",
       "      <td>42</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>6453</td>\n",
       "      <td>[6456, 6453, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>method2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.983302</td>\n",
       "      <td>0.189664</td>\n",
       "      <td>0.250651</td>\n",
       "      <td>0.621024</td>\n",
       "      <td>38</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>6453</td>\n",
       "      <td>[6456, 6453, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>method2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.981938</td>\n",
       "      <td>0.180780</td>\n",
       "      <td>0.276289</td>\n",
       "      <td>0.653387</td>\n",
       "      <td>37</td>\n",
       "      <td>0.002862</td>\n",
       "      <td>6453</td>\n",
       "      <td>[6456, 6453, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>method2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980626</td>\n",
       "      <td>0.173247</td>\n",
       "      <td>0.301342</td>\n",
       "      <td>0.683850</td>\n",
       "      <td>36</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>6453</td>\n",
       "      <td>[6456, 6453, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>method2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0.979203</td>\n",
       "      <td>0.166647</td>\n",
       "      <td>0.326287</td>\n",
       "      <td>0.713285</td>\n",
       "      <td>36</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>6454</td>\n",
       "      <td>[6456, 6454, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>method2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.977702</td>\n",
       "      <td>0.160378</td>\n",
       "      <td>0.350857</td>\n",
       "      <td>0.739278</td>\n",
       "      <td>34</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>6454</td>\n",
       "      <td>[6457, 6454, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>method2</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975907</td>\n",
       "      <td>0.154787</td>\n",
       "      <td>0.374650</td>\n",
       "      <td>0.763293</td>\n",
       "      <td>33</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>6454</td>\n",
       "      <td>[6459, 6454, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>method2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.973868</td>\n",
       "      <td>0.149435</td>\n",
       "      <td>0.398418</td>\n",
       "      <td>0.785290</td>\n",
       "      <td>33</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>6454</td>\n",
       "      <td>[6459, 6454, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>method2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971890</td>\n",
       "      <td>0.144612</td>\n",
       "      <td>0.421592</td>\n",
       "      <td>0.805784</td>\n",
       "      <td>32</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>6455</td>\n",
       "      <td>[6459, 6455, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>method2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969496</td>\n",
       "      <td>0.140312</td>\n",
       "      <td>0.444230</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>29</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>6456</td>\n",
       "      <td>[6459, 6456, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>method2</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966986</td>\n",
       "      <td>0.136146</td>\n",
       "      <td>0.466770</td>\n",
       "      <td>0.844160</td>\n",
       "      <td>29</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>6456</td>\n",
       "      <td>[6460, 6456, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>method2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0.964084</td>\n",
       "      <td>0.132258</td>\n",
       "      <td>0.488367</td>\n",
       "      <td>0.860579</td>\n",
       "      <td>29</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>6456</td>\n",
       "      <td>[6460, 6456, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>method2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.960720</td>\n",
       "      <td>0.128394</td>\n",
       "      <td>0.509397</td>\n",
       "      <td>0.874466</td>\n",
       "      <td>27</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>6456</td>\n",
       "      <td>[6460, 6456, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   description  n_neighbors  repeat_time  precision  nr_precision    recall  \\\n",
       "0      method2            2            1   0.991741      0.329212  0.061024   \n",
       "1      method2            3            1   0.990384      0.289709  0.089456   \n",
       "2      method2            4            1   0.989292      0.262620  0.117521   \n",
       "3      method2            5            1   0.988453      0.241728  0.145013   \n",
       "4      method2            6            1   0.987347      0.225588  0.171849   \n",
       "5      method2            7            1   0.986080      0.211258  0.198553   \n",
       "6      method2            8            1   0.984737      0.199347  0.224752   \n",
       "7      method2            9            1   0.983302      0.189664  0.250651   \n",
       "8      method2           10            1   0.981938      0.180780  0.276289   \n",
       "9      method2           11            1   0.980626      0.173247  0.301342   \n",
       "10     method2           12            1   0.979203      0.166647  0.326287   \n",
       "11     method2           13            1   0.977702      0.160378  0.350857   \n",
       "12     method2           14            1   0.975907      0.154787  0.374650   \n",
       "13     method2           15            1   0.973868      0.149435  0.398418   \n",
       "14     method2           16            1   0.971890      0.144612  0.421592   \n",
       "15     method2           17            1   0.969496      0.140312  0.444230   \n",
       "16     method2           18            1   0.966986      0.136146  0.466770   \n",
       "17     method2           19            1   0.964084      0.132258  0.488367   \n",
       "18     method2           20            1   0.960720      0.128394  0.509397   \n",
       "\n",
       "    nr_recall  singleton_count  singleton_fraction   N50  \\\n",
       "0    0.260207              124            0.009593   207   \n",
       "1    0.336129               78            0.006034  1255   \n",
       "2    0.400736               59            0.004564  3954   \n",
       "3    0.455531               50            0.003868  3955   \n",
       "4    0.504352               48            0.003713  6451   \n",
       "5    0.546408               43            0.003327  6452   \n",
       "6    0.584428               42            0.003249  6453   \n",
       "7    0.621024               38            0.002940  6453   \n",
       "8    0.653387               37            0.002862  6453   \n",
       "9    0.683850               36            0.002785  6453   \n",
       "10   0.713285               36            0.002785  6454   \n",
       "11   0.739278               34            0.002630  6454   \n",
       "12   0.763293               33            0.002553  6454   \n",
       "13   0.785290               33            0.002553  6454   \n",
       "14   0.805784               32            0.002476  6455   \n",
       "15   0.825843               29            0.002244  6456   \n",
       "16   0.844160               29            0.002244  6456   \n",
       "17   0.860579               29            0.002244  6456   \n",
       "18   0.874466               27            0.002089  6456   \n",
       "\n",
       "                                      component_sizes  \n",
       "0   [777, 567, 551, 433, 423, 407, 345, 325, 310, ...  \n",
       "1   [2791, 2093, 1285, 1255, 1206, 1201, 1163, 115...  \n",
       "2   [5162, 3954, 1289, 1286, 1206, 1, 1, 1, 1, 1, ...  \n",
       "3   [6450, 3955, 2496, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4   [6453, 6451, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "5   [6455, 6452, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "6   [6456, 6453, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "7   [6456, 6453, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "8   [6456, 6453, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "9   [6456, 6453, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "10  [6456, 6454, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "11  [6457, 6454, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "12  [6459, 6454, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "13  [6459, 6454, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "14   [6459, 6455, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "15      [6459, 6456, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "16         [6460, 6456, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "17         [6460, 6456, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  \n",
       "18         [6460, 6456, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vptree_indices[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=42)\n",
    "\n",
    "dimension = 32 # 32 bytes are 256 bit dimensional vectos\n",
    "num_points = 2021\n",
    "data = np.random.normal(scale=255, loc=0, size=(num_points, dimension)).astype(dtype=np.uint8)\n",
    "\n",
    "num_queries = 8\n",
    "queries = np.random.normal(scale=255, loc=0, size=(num_queries, dimension)).astype(dtype=np.uint8)\n",
    "\n",
    "k = 2\n",
    "\n",
    "vptree = pynear.VPTreeBinaryIndex()\n",
    "vptree.set(data)\n",
    "vptree_indices, vptree_distances = vptree.searchKNN(queries, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[126, 221, 165, ..., 182, 103, 216],\n",
       "       [253, 243, 209, ..., 209, 230, 207],\n",
       "       [207,  89, 238, ..., 173, 157, 139],\n",
       "       ...,\n",
       "       [ 79, 145, 223, ...,   0, 162,  59],\n",
       "       [ 68,   9,  84, ...,  30, 218,  44],\n",
       "       [ 34, 107, 189, ...,  17,  79, 247]], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vptree\n",
    "tree = vptree.VPTree(reads_simhash_array, hamming_distance)\n",
    "tree.get_n_nearest_neighbors(list(reads_simhash_array[1]), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#df_tfidf.to_csv('/home/miaocj/docker_dir/kNN-overlap-finder/data/evaluation/human/HLA/ONT_R9/kmer_k16/SimHash_None_None_overlap_stat.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vptree\n",
      "  Using cached vptree-1.3.tar.gz (4.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/4506eccf78279d93d0e8a34c035e91c5_/lib/python3.10/site-packages (from vptree) (1.26.4)\n",
      "Building wheels for collected packages: vptree\n",
      "  Building wheel for vptree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for vptree: filename=vptree-1.3-py3-none-any.whl size=4546 sha256=5cc08ad90292e727e0c327e5ad689a94de66da6853727abeac950b9ffbd385d8\n",
      "  Stored in directory: /home/miaocj/.cache/pip/wheels/3a/eb/ca/904b67530bad0ab02a61978e03549e80bfb1ae07363edb3aab\n",
      "Successfully built vptree\n",
      "Installing collected packages: vptree\n",
      "Successfully installed vptree-1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vptree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 1, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 1, 0],\n",
       "       [1, 0, 0, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 1, 1, ..., 1, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 1, 0, 1]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reads_simhash_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = np.random.randn(20000, 10)\n",
    "query = [.5] * 10\n",
    "reads_simhash_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12926"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reads_simhash_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import vptree\n",
    "\n",
    "# Define distance function.\n",
    "def euclidean(p1, p2):\n",
    "  return np.sqrt(np.sum(np.power(p2 - p1, 2)))\n",
    "\n",
    "# Generate some random points.\n",
    "points = np.random.randn(12926, 3200)\n",
    "query = [.5] * 3200\n",
    "\n",
    "# Build tree in O(n log n) time complexity.\n",
    "tree = vptree.VPTree(points, hamming_distance)\n",
    "\n",
    "# Query single point.\n",
    "tree.get_nearest_neighbor(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "##法一 ：哈希长度为1028\n",
    "df\n",
    "df.to_csv('/home/miaocj/docker_dir/kNN-overlap-finder/data/evaluation/human/HLA/ONT_R9/kmer_k16/SimHash_method1_overlap_stat.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>repeat_time</th>\n",
       "      <th>precision</th>\n",
       "      <th>nr_precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>nr_recall</th>\n",
       "      <th>singleton_count</th>\n",
       "      <th>singleton_fraction</th>\n",
       "      <th>N50</th>\n",
       "      <th>component_sizes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.959684</td>\n",
       "      <td>0.290254</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.232711</td>\n",
       "      <td>565</td>\n",
       "      <td>0.043710</td>\n",
       "      <td>455</td>\n",
       "      <td>[857, 725, 718, 686, 665, 615, 557, 514, 463, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.953179</td>\n",
       "      <td>0.260759</td>\n",
       "      <td>0.086906</td>\n",
       "      <td>0.305389</td>\n",
       "      <td>457</td>\n",
       "      <td>0.035355</td>\n",
       "      <td>1514</td>\n",
       "      <td>[3303, 2452, 1514, 1178, 1063, 880, 596, 588, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.947717</td>\n",
       "      <td>0.237915</td>\n",
       "      <td>0.113280</td>\n",
       "      <td>0.365287</td>\n",
       "      <td>394</td>\n",
       "      <td>0.030481</td>\n",
       "      <td>6223</td>\n",
       "      <td>[6362, 6223, 134, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.942152</td>\n",
       "      <td>0.219366</td>\n",
       "      <td>0.138751</td>\n",
       "      <td>0.414979</td>\n",
       "      <td>363</td>\n",
       "      <td>0.028083</td>\n",
       "      <td>6366</td>\n",
       "      <td>[6366, 6366, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>0.936710</td>\n",
       "      <td>0.205125</td>\n",
       "      <td>0.163604</td>\n",
       "      <td>0.460199</td>\n",
       "      <td>336</td>\n",
       "      <td>0.025994</td>\n",
       "      <td>6369</td>\n",
       "      <td>[6373, 6369, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.931507</td>\n",
       "      <td>0.193302</td>\n",
       "      <td>0.188038</td>\n",
       "      <td>0.501226</td>\n",
       "      <td>320</td>\n",
       "      <td>0.024756</td>\n",
       "      <td>6376</td>\n",
       "      <td>[6377, 6376, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>8</td>\n",
       "      <td>100</td>\n",
       "      <td>0.926592</td>\n",
       "      <td>0.182611</td>\n",
       "      <td>0.211843</td>\n",
       "      <td>0.536279</td>\n",
       "      <td>305</td>\n",
       "      <td>0.023596</td>\n",
       "      <td>6379</td>\n",
       "      <td>[6381, 6379, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>0.921660</td>\n",
       "      <td>0.173825</td>\n",
       "      <td>0.235100</td>\n",
       "      <td>0.569552</td>\n",
       "      <td>289</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>6382</td>\n",
       "      <td>[6383, 6382, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.916555</td>\n",
       "      <td>0.165750</td>\n",
       "      <td>0.257791</td>\n",
       "      <td>0.598829</td>\n",
       "      <td>280</td>\n",
       "      <td>0.021662</td>\n",
       "      <td>6385</td>\n",
       "      <td>[6391, 6385, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>0.911067</td>\n",
       "      <td>0.158549</td>\n",
       "      <td>0.279779</td>\n",
       "      <td>0.625415</td>\n",
       "      <td>270</td>\n",
       "      <td>0.020888</td>\n",
       "      <td>6385</td>\n",
       "      <td>[6393, 6385, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>0.905279</td>\n",
       "      <td>0.152342</td>\n",
       "      <td>0.301225</td>\n",
       "      <td>0.651132</td>\n",
       "      <td>260</td>\n",
       "      <td>0.020114</td>\n",
       "      <td>6386</td>\n",
       "      <td>[6394, 6386, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>13</td>\n",
       "      <td>100</td>\n",
       "      <td>0.899126</td>\n",
       "      <td>0.146115</td>\n",
       "      <td>0.322163</td>\n",
       "      <td>0.672496</td>\n",
       "      <td>252</td>\n",
       "      <td>0.019496</td>\n",
       "      <td>6390</td>\n",
       "      <td>[6396, 6390, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>14</td>\n",
       "      <td>100</td>\n",
       "      <td>0.892496</td>\n",
       "      <td>0.140563</td>\n",
       "      <td>0.342411</td>\n",
       "      <td>0.692712</td>\n",
       "      <td>242</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>6392</td>\n",
       "      <td>[6399, 6392, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.885593</td>\n",
       "      <td>0.135371</td>\n",
       "      <td>0.362105</td>\n",
       "      <td>0.710991</td>\n",
       "      <td>236</td>\n",
       "      <td>0.018258</td>\n",
       "      <td>6396</td>\n",
       "      <td>[6401, 6396, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>16</td>\n",
       "      <td>100</td>\n",
       "      <td>0.878061</td>\n",
       "      <td>0.130378</td>\n",
       "      <td>0.381071</td>\n",
       "      <td>0.726816</td>\n",
       "      <td>230</td>\n",
       "      <td>0.017794</td>\n",
       "      <td>6399</td>\n",
       "      <td>[6402, 6399, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>17</td>\n",
       "      <td>100</td>\n",
       "      <td>0.870282</td>\n",
       "      <td>0.126079</td>\n",
       "      <td>0.399185</td>\n",
       "      <td>0.742839</td>\n",
       "      <td>226</td>\n",
       "      <td>0.017484</td>\n",
       "      <td>6401</td>\n",
       "      <td>[6404, 6401, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>18</td>\n",
       "      <td>100</td>\n",
       "      <td>0.861322</td>\n",
       "      <td>0.121919</td>\n",
       "      <td>0.416150</td>\n",
       "      <td>0.756647</td>\n",
       "      <td>221</td>\n",
       "      <td>0.017097</td>\n",
       "      <td>6405</td>\n",
       "      <td>[6406, 6405, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>19</td>\n",
       "      <td>100</td>\n",
       "      <td>0.852184</td>\n",
       "      <td>0.117797</td>\n",
       "      <td>0.432893</td>\n",
       "      <td>0.768634</td>\n",
       "      <td>219</td>\n",
       "      <td>0.016943</td>\n",
       "      <td>6405</td>\n",
       "      <td>[6407, 6405, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SimHash_TF-IDF</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>0.842065</td>\n",
       "      <td>0.113954</td>\n",
       "      <td>0.448527</td>\n",
       "      <td>0.779672</td>\n",
       "      <td>212</td>\n",
       "      <td>0.016401</td>\n",
       "      <td>6405</td>\n",
       "      <td>[6407, 6405, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       description  n_neighbors  repeat_time  precision  nr_precision  \\\n",
       "0   SimHash_TF-IDF            2          100   0.959684      0.290254   \n",
       "1   SimHash_TF-IDF            3          100   0.953179      0.260759   \n",
       "2   SimHash_TF-IDF            4          100   0.947717      0.237915   \n",
       "3   SimHash_TF-IDF            5          100   0.942152      0.219366   \n",
       "4   SimHash_TF-IDF            6          100   0.936710      0.205125   \n",
       "5   SimHash_TF-IDF            7          100   0.931507      0.193302   \n",
       "6   SimHash_TF-IDF            8          100   0.926592      0.182611   \n",
       "7   SimHash_TF-IDF            9          100   0.921660      0.173825   \n",
       "8   SimHash_TF-IDF           10          100   0.916555      0.165750   \n",
       "9   SimHash_TF-IDF           11          100   0.911067      0.158549   \n",
       "10  SimHash_TF-IDF           12          100   0.905279      0.152342   \n",
       "11  SimHash_TF-IDF           13          100   0.899126      0.146115   \n",
       "12  SimHash_TF-IDF           14          100   0.892496      0.140563   \n",
       "13  SimHash_TF-IDF           15          100   0.885593      0.135371   \n",
       "14  SimHash_TF-IDF           16          100   0.878061      0.130378   \n",
       "15  SimHash_TF-IDF           17          100   0.870282      0.126079   \n",
       "16  SimHash_TF-IDF           18          100   0.861322      0.121919   \n",
       "17  SimHash_TF-IDF           19          100   0.852184      0.117797   \n",
       "18  SimHash_TF-IDF           20          100   0.842065      0.113954   \n",
       "\n",
       "      recall  nr_recall  singleton_count  singleton_fraction   N50  \\\n",
       "0   0.059900   0.232711              565            0.043710   455   \n",
       "1   0.086906   0.305389              457            0.035355  1514   \n",
       "2   0.113280   0.365287              394            0.030481  6223   \n",
       "3   0.138751   0.414979              363            0.028083  6366   \n",
       "4   0.163604   0.460199              336            0.025994  6369   \n",
       "5   0.188038   0.501226              320            0.024756  6376   \n",
       "6   0.211843   0.536279              305            0.023596  6379   \n",
       "7   0.235100   0.569552              289            0.022358  6382   \n",
       "8   0.257791   0.598829              280            0.021662  6385   \n",
       "9   0.279779   0.625415              270            0.020888  6385   \n",
       "10  0.301225   0.651132              260            0.020114  6386   \n",
       "11  0.322163   0.672496              252            0.019496  6390   \n",
       "12  0.342411   0.692712              242            0.018722  6392   \n",
       "13  0.362105   0.710991              236            0.018258  6396   \n",
       "14  0.381071   0.726816              230            0.017794  6399   \n",
       "15  0.399185   0.742839              226            0.017484  6401   \n",
       "16  0.416150   0.756647              221            0.017097  6405   \n",
       "17  0.432893   0.768634              219            0.016943  6405   \n",
       "18  0.448527   0.779672              212            0.016401  6405   \n",
       "\n",
       "                                      component_sizes  \n",
       "0   [857, 725, 718, 686, 665, 615, 557, 514, 463, ...  \n",
       "1   [3303, 2452, 1514, 1178, 1063, 880, 596, 588, ...  \n",
       "2   [6362, 6223, 134, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1...  \n",
       "3   [6366, 6366, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, ...  \n",
       "4   [6373, 6369, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "5   [6377, 6376, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "6   [6381, 6379, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "7   [6383, 6382, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "8   [6391, 6385, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "9   [6393, 6385, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "10  [6394, 6386, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "11  [6396, 6390, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "12  [6399, 6392, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "13  [6401, 6396, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "14  [6402, 6399, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "15  [6404, 6401, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "16  [6406, 6405, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "17  [6407, 6405, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "18  [6407, 6405, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_reads_simhash_array = get_simhash(ref_read_features,hash_table)\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=1, algorithm='auto', metric=hamming_distance)\n",
    "nbrs.fit(ref_reads_simhash_array)\n",
    "indices = nbrs.kneighbors(que_reads_simhash_array,return_distance=False)\n",
    "print(\"done\\nevaluates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hash(kmer_index: int, seed: int) -> np.ndarray:  \n",
    "    hash_value = mmh3.hash(str(kmer_index), seed=seed)\n",
    "    binary_string = \"{0:032b}\".format(hash_value & 0xFFFFFFFF)  \n",
    "    hash_array = np.array([int(x) for x in binary_string], dtype=np.int8) \n",
    "    hash_array = np.where(hash_array == 0, -1, 1)  \n",
    "    return hash_array  \n",
    "\n",
    "def _get_table(\n",
    "    read_features: list,  \n",
    "    feature_matrix: list,\n",
    "    *,\n",
    "    seed: int,\n",
    "    tf:bool,\n",
    "    idf:bool,\n",
    "    repeat=100) -> Mapping[int,list]:  \n",
    "    \n",
    "    rng = np.random.default_rng(seed)  \n",
    "    hash_seeds = rng.integers(low=0, high=2**32 - 1, size=repeat, dtype=np.uint64)  \n",
    "\n",
    "    kmer_num = feature_matrix.shape[1]\n",
    "    hash_table = np.empty((kmer_num,repeat,32),dtype=np.int8)  \n",
    "    for flag,seed in enumerate(hash_seeds):\n",
    "        for kmer_index in range(kmer_num):\n",
    "            hash_table[kmer_index,flag,:]=_hash(kmer_index, seed=seed)\n",
    "            new_hash_table=np.reshape(hash_table,(kmer_num,3200))\n",
    "    return new_hash_table\n",
    "\n",
    "def _get_simhash(\n",
    "    read_features: list,  \n",
    "    feature_matrix: list,\n",
    "    hash_table,\n",
    "    *,\n",
    "    seed: int,\n",
    "    tf:bool,\n",
    "    idf:bool,\n",
    "    repeat=100) -> Mapping[int,list]:  \n",
    "    all_read_simhash = []\n",
    "    if idf == True:\n",
    "        nested_list = list(read_features.values())\n",
    "        unrongh_nest = [list(set(sublist)) for sublist in nested_list]  \n",
    "        merged_list = list(chain.from_iterable(unrongh_nest)) \n",
    "        count = Counter(merged_list)\n",
    "        sorted_counts = dict(sorted(count.items(), key=lambda x: x[0]))  \n",
    "        times = np.array(list(sorted_counts.values()))\n",
    "        x = len(read_features)\n",
    "        arr = np.full(feature_matrix.shape[1],x)  \n",
    "        idf = np.log(arr/times)\n",
    "        weighted_hash_table = hash_table*idf[:, np.newaxis]\n",
    "    else:\n",
    "        weighted_hash_table = hash_table\n",
    "    if tf == False:\n",
    "        read_features = {k:list(set(v)) for k,v in read_features.items()}\n",
    "\n",
    "    for read_kmer in read_features.values():\n",
    "        one_read_hash = np.sum(weighted_hash_table[read_kmer,:],axis=0)\n",
    "        simhash = np.where(one_read_hash > 0, 1, 0)\n",
    "        all_read_simhash.append(simhash)\n",
    "    reads_simhash_array = np.array(all_read_simhash)\n",
    "\n",
    "    return reads_simhash_array \n",
    "\n",
    "hash_table = _get_table(read_features,feature_matrix,seed = 15232,tf = False,idf=False,repeat=100)\n",
    "print(\"1\")\n",
    "reads_simhash_array = _get_simhash(read_features,feature_matrix,hash_table,seed = 15232,tf = True,idf=False,repeat=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hash(kmer_index: int, seed: int) -> np.ndarray:  \n",
    "    hash_value = mmh3.hash(str(kmer_index), seed=seed)\n",
    "    binary_string = \"{0:032b}\".format(hash_value & 0xFFFFFFFF)  \n",
    "    hash_array = np.array([int(x) for x in binary_string], dtype=np.int8) \n",
    "    hash_array = np.where(hash_array == 0, -1, 1)  \n",
    "    return hash_array  \n",
    "def mp_get_hashtable(  \n",
    "    feature_matrix: list,   \n",
    "    repeat: int,   \n",
    "    seed: int,\n",
    "    processes:int,) -> Mapping[int,list]:  \n",
    "      \n",
    "    rng = np.random.default_rng(seed)  \n",
    "    hash_seeds = rng.integers(low=0, high=2**32 - 1, size=repeat, dtype=np.uint64)  \n",
    "    kmer_num = feature_matrix.shape[1]\n",
    "    hash_table = np.empty((kmer_num,repeat,32),dtype=np.int8) \n",
    "\n",
    "    with sharedmem.MapReduce(np=processes) as pool:\n",
    "\n",
    "        def work(i):\n",
    "            seed = hash_seeds[i]\n",
    "            result = np.empty((kmer_num,32), dtype=np.int8) \n",
    "            for kmer_index in range(kmer_num):\n",
    "                result[kmer_index,:]=_hash(kmer_index, seed=seed)\n",
    "            return i,result\n",
    "\n",
    "        def reduce(i, result):\n",
    "            hash_table[:,i,:] = result            \n",
    "\n",
    "        pool.map(work, range(repeat), reduce=reduce)\n",
    "    return hash_table\n",
    "hash_table = mp_get_hashtable(read_features,feature_matrix,15232,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_read_hash = np.sum(hash_table[list(read_features.values())[0],:,:],axis=0)\n",
    "hash_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer_num = feature_matrix.shape[1]\n",
    "hash_table=np.reshape(hash_table,(kmer_num,3200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_hash[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_read_intervals(meta_df):\n",
    "    read_intervals = {\n",
    "        i: [GenomicInterval(strand, start, end)]\n",
    "        for i, strand, start, end in zip(\n",
    "            meta_df.index,\n",
    "            meta_df[\"reference_strand\"],\n",
    "            meta_df[\"reference_start\"],\n",
    "            meta_df[\"reference_end\"],\n",
    "        )\n",
    "    }\n",
    "    return read_intervals\n",
    "\n",
    "read_intervals = get_read_intervals(meta_df)\n",
    "\n",
    "reference_graph = OverlapGraph.from_intervals(read_intervals)\n",
    "nr_edges = set((node_1, node_2) for node_1, node_2, data in reference_graph.edges(data=True) if not data['redundant'])\n",
    "connected_component_count = len(list(nx.connected_components(reference_graph)))\n",
    "len(reference_graph.nodes), len(reference_graph.edges), len(nr_edges), connected_component_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_ids = np.array(list(read_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hash(kmer_index: int, seed: int) -> np.ndarray:  \n",
    "    hash_value = mmh3.hash(str(kmer_index), seed=seed)\n",
    "    binary_string = \"{0:032b}\".format(hash_value & 0xFFFFFFFF)  \n",
    "    hash_array = np.array([int(x) for x in binary_string], dtype=np.int32) \n",
    "    hash_array = np.where(hash_array == 0, -1, 1)  \n",
    "    return hash_array  \n",
    "\n",
    "def mp_get_hashtable(  \n",
    "    feature_matrix: list,   \n",
    "    repeat: int,   \n",
    "    seed: int,\n",
    "    processes:int,) -> Mapping[int,list]:  \n",
    "      \n",
    "    rng = np.random.default_rng(seed)  \n",
    "    hash_seeds = rng.integers(low=0, high=2**32 - 1, size=repeat, dtype=np.uint64)  \n",
    "    kmer_num = feature_matrix.shape[1]\n",
    "    hash_table = np.empty((kmer_num,repeat),dtype=object) \n",
    "\n",
    "    with sharedmem.MapReduce(np=processes) as pool:\n",
    "\n",
    "        def work(i):\n",
    "            seed = hash_seeds[i]\n",
    "            result = np.empty(kmer_num, dtype=object) \n",
    "            for kmer_index in range(kmer_num):\n",
    "                result[kmer_index]=_hash(kmer_index, seed=seed)\n",
    "            return i,result\n",
    "\n",
    "        def reduce(i, result):\n",
    "            hash_table[:,i] = result            \n",
    "\n",
    "        pool.map(work, range(repeat), reduce=reduce)\n",
    "    return hash_table\n",
    "\n",
    "def hamming_distance(x, y):  \n",
    "    return np.count_nonzero(x != y)\n",
    "\n",
    "## multi-process calculate simhash value\n",
    "def mp_get_simhash(\n",
    "    read_features: list,  \n",
    "    feature_matrix: list,\n",
    "    hash_table,\n",
    "    tf:bool,\n",
    "    idf:bool,\n",
    "    processes:int,):\n",
    "    \n",
    "    if idf == True:\n",
    "        nested_list = list(read_features.values())\n",
    "        unrongh_nest = [list(set(sublist)) for sublist in nested_list]  \n",
    "        merged_list = list(chain.from_iterable(unrongh_nest)) \n",
    "        count = Counter(merged_list)\n",
    "        sorted_counts = dict(sorted(count.items(), key=lambda x: x[0]))  \n",
    "        times = np.array(list(sorted_counts.values()))\n",
    "        x = len(read_features)\n",
    "        arr = np.full(feature_matrix.shape[1],x)  \n",
    "        idf = np.log(arr/times)\n",
    "        hash_table = hash_table*idf[:, np.newaxis]\n",
    "    if tf == False:\n",
    "        read_features = {k:list(set(v)) for k,v in read_features.items()} \n",
    "\n",
    "       \n",
    "    reads_simhash_array = np.empty((len(read_features),hash_table.shape[1]*32),dtype=object)\n",
    "    with sharedmem.MapReduce(np=processes) as pool:\n",
    "\n",
    "        def work(i):\n",
    "            read_kmer = list(read_features.values())[i]\n",
    "            one_read_hash = np.sum(hash_table[read_kmer,:],axis=0)\n",
    "            conc_hash = np.concatenate(one_read_hash)\n",
    "            result = np.where(conc_hash > 0, 1, 0)\n",
    "            return i,result\n",
    "\n",
    "        def reduce(i, result):\n",
    "            reads_simhash_array[i,:] = result            \n",
    "        pool.map(work, range(len(read_features)), reduce=reduce)\n",
    "    return reads_simhash_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_table = mp_get_hashtable(feature_matrix,repeat =100, seed = 4829,processes=12)\n",
    "print('hashtable established')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import collections  \n",
    "from typing import Mapping  \n",
    "from sklearn.neighbors import NearestNeighbors  \n",
    "from scipy.spatial.distance import hamming  \n",
    "import mmh3\n",
    "\n",
    "for repeat in [100]:\n",
    "    print(repeat)\n",
    "    concat_simhash = _get_simhash(read_features,feature_matrix,repeat =repeat, seed = 4829,tf = True,idf = True)\n",
    "    nbrs = NearestNeighbors(n_neighbors=21, algorithm='auto', metric=hamming_distance)\n",
    "    nbrs.fit(concat_simhash)  \n",
    "    indices = nbrs.kneighbors(concat_simhash,return_distance=False)\n",
    "    nbr_indices = indices[:, 1:]\n",
    "\n",
    "    for k in k_values:\n",
    "        graph = OverlapGraph.from_neighbor_indices(\n",
    "            neighbor_indices=nbr_indices,\n",
    "            n_neighbors=k,\n",
    "            read_ids=read_ids,\n",
    "            require_mutual_neighbors=False,\n",
    "        )\n",
    "        graph_stats = get_overlap_statistics(query_graph=graph, reference_graph=reference_graph)\n",
    "        stats = { \"n_neighbors\": k}\n",
    "        stats = {\"description\":'SimHash', \"n_neighbors\": k, \"repeat_time\": repeat,\n",
    "                    **graph_stats}\n",
    "        df_rows.append(stats)\n",
    "    df = pd.DataFrame(df_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat = 100\n",
    "\n",
    "def _hash(kmer_index: int, seed: int) -> np.ndarray:  \n",
    "    hash_value = mmh3.hash(str(kmer_index), seed=seed)\n",
    "    binary_string = \"{0:032b}\".format(hash_value & 0xFFFFFFFF)  \n",
    "    hash_array = np.array([int(x) for x in binary_string], dtype=np.int32) \n",
    "    hash_array = np.where(hash_array == 0, -1, 1)  \n",
    "    return hash_array  \n",
    "\n",
    "all_read_simhash = []\n",
    "rng = np.random.default_rng(4829)  \n",
    "hash_seeds = rng.integers(low=0, high=2**32 - 1, size=repeat, dtype=np.uint64)\n",
    "kmer_num = feature_matrix.shape[1]\n",
    "hash_table = np.empty((kmer_num,repeat),dtype=object)  \n",
    "for flag,seed in enumerate(hash_seeds):\n",
    "    print(flag)\n",
    "    kmer_hash_indice = {} \n",
    "    for kmer_index in range(kmer_num):\n",
    "        hash_table[kmer_index,flag]=_hash(kmer_index, seed=seed)\n",
    "new_hash = hash_table*idf[:, np.newaxis]\n",
    "\n",
    "for read_ind,read_kmer in read_features.items():\n",
    "    one_read_hash = np.sum(new_hash[read_kmer,:],axis=0)\n",
    "    conc_hash = np.concatenate(one_read_hash)\n",
    "    simhash = np.where(conc_hash > 0, 1, 0)\n",
    "    all_read_simhash.append(simhash)\n",
    "reads_simhash_array = np.array(all_read_simhash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reads_simhash_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=21, algorithm='auto', metric=hamming_distance)\n",
    "nbrs.fit(reads_simhash_array)  \n",
    "indices = nbrs.kneighbors(reads_simhash_array,return_distance=False)\n",
    "nbr_indices = indices[:, 1:]\n",
    "\n",
    "read_ids = np.array(list(read_features))\n",
    "k_values = np.arange(2, max_n_neighbors + 1)\n",
    "df_rows = []\n",
    "\n",
    "for k in k_values:\n",
    "    graph = OverlapGraph.from_neighbor_indices(\n",
    "        neighbor_indices=nbr_indices,\n",
    "        n_neighbors=k,\n",
    "        read_ids=read_ids,\n",
    "        require_mutual_neighbors=False,\n",
    "    )\n",
    "    graph_stats = get_overlap_statistics(query_graph=graph, reference_graph=reference_graph)\n",
    "    stats = { \"n_neighbors\": k}\n",
    "    stats = {\"description\":'SimHash', \"n_neighbors\": k, \"repeat_time\": repeat,\n",
    "                **graph_stats}\n",
    "    df_rows.append(stats)\n",
    "df = pd.DataFrame(df_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##带tf idf 初始版本\n",
    "def _hash(kmer_index: int, seed: int) -> np.ndarray:  \n",
    "    hash_value = mmh3.hash(str(kmer_index), seed=seed)\n",
    "    binary_string = \"{0:032b}\".format(hash_value & 0xFFFFFFFF)  \n",
    "    hash_array = np.array([int(x) for x in binary_string], dtype=np.int32) \n",
    "    hash_array = np.where(hash_array == 0, -1, 1)  \n",
    "    return hash_array  \n",
    "\n",
    "def _get_simhash(  \n",
    "    read_features: list,  \n",
    "    feature_matrix: list,   \n",
    "    repeat: int,   \n",
    "    seed: int,\n",
    "    tf:bool,\n",
    "    idf:bool,) -> Mapping[int,list]:  \n",
    "      \n",
    "    rng = np.random.default_rng(seed)  \n",
    "    hash_seeds = rng.integers(low=0, high=2**32 - 1, size=repeat, dtype=np.uint64)  \n",
    "  \n",
    "    all_read_simhash = []\n",
    "    kmer_num = feature_matrix.shape[1]\n",
    "    hash_table = np.empty((kmer_num,repeat),dtype=object)  \n",
    "    for flag,seed in enumerate(hash_seeds):\n",
    "        for kmer_index in range(kmer_num):\n",
    "            hash_table[kmer_index,flag]=_hash(kmer_index, seed=seed)\n",
    "\n",
    "    if idf == True:\n",
    "        nested_list = list(read_features.values())\n",
    "        unrongh_nest = [list(set(sublist)) for sublist in nested_list]  \n",
    "        merged_list = list(chain.from_iterable(unrongh_nest)) \n",
    "        count = Counter(merged_list)\n",
    "        sorted_counts = dict(sorted(count.items(), key=lambda x: x[0]))  \n",
    "        times = np.array(list(sorted_counts.values()))\n",
    "        x = len(read_features)\n",
    "        arr = np.full(feature_matrix.shape[1],x)  \n",
    "        idf = np.log(arr/times)\n",
    "        hash_table = hash_table*idf[:, np.newaxis]\n",
    "    if tf == False:\n",
    "        read_features = {k:set(v) for k,v in read_features}\n",
    "\n",
    "    for read_kmer in read_features.values():\n",
    "        one_read_hash = np.sum(hash_table[read_kmer,:],axis=0)\n",
    "        conc_hash = np.concatenate(one_read_hash)\n",
    "        simhash = np.where(conc_hash > 0, 1, 0)\n",
    "        all_read_simhash.append(simhash)\n",
    "    reads_simhash_array = np.array(all_read_simhash)\n",
    "  \n",
    "    return reads_simhash_array \n",
    "\n",
    "def hamming_distance(x, y):  \n",
    "    return np.count_nonzero(x != y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new[3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##32位，70个repeat\n",
    "import numpy as np  \n",
    "import collections  \n",
    "from typing import Mapping  \n",
    "from sklearn.neighbors import NearestNeighbors  \n",
    "from scipy.spatial.distance import hamming  \n",
    "import mmh3  \n",
    "\n",
    "def _hash(kmer_index: int, seed: int) -> np.ndarray:  \n",
    "    hash_value = mmh3.hash(str(kmer_index), seed=seed)  \n",
    "    binary_string = \"{0:032b}\".format(hash_value & 0xFFFFFFFF)  \n",
    "    hash_array = np.array([int(x) for x in binary_string], dtype=np.int32)  \n",
    "    return hash_array  \n",
    "\n",
    "def _get_simhash(  \n",
    "    read_features: list,  \n",
    "    feature_matrix: list,   \n",
    "    repeat: int,   \n",
    "    seed: int) -> Mapping[int,list]:  \n",
    "\n",
    "    hash_seeds = np.array(range(repeat))\n",
    "    kmer_num = feature_matrix.shape[1]\n",
    "    kmer_index = np.array(range(kmer_num))\n",
    "\n",
    "    table = []\n",
    "    for seed in hash_seeds:\n",
    "        prime1 = 2654435761  # A large prime number\n",
    "        prime2 = 0x27d4eb2d  # Another large prime, often used in hashing\n",
    "        hash_value = (kmer_index * prime1) ^ (seed * prime2)\n",
    "        hash_t = hash_value % (2**32)\n",
    "        binary_matrix = np.vectorize(np.binary_repr)(hash_t, width=32)\n",
    "        one_repear_table = np.array([list(row) for row in binary_matrix.flatten()])\n",
    "        table.append(one_repear_table.astype(int))\n",
    "    hash_table = np.hstack(table)\n",
    "\n",
    "    all_read_simhash = []\n",
    "    for read_ind,read_kmer in read_features.items():\n",
    "        one_read_hash = np.sum(hash_table[read_kmer,:],axis=0)\n",
    "        simhash = np.where(conc_hash > 0, 1, 0)\n",
    "        all_read_simhash.append(simhash)\n",
    "    concat_simhash = np.array(all_read_simhash)\n",
    "    return concat_simhash \n",
    "\n",
    "def hamming_distance(x, y):  \n",
    "    return np.count_nonzero(x != y)\n",
    "\n",
    "dfs = []\n",
    "for repeat in range(20,110,10):\n",
    "    print(repeat)\n",
    "    concat_simhash = _get_simhash(read_features,feature_matrix,repeat =repeat, seed = 4829)\n",
    "    nbrs = NearestNeighbors(n_neighbors=21, algorithm='auto', metric=hamming_distance)\n",
    "    nbrs.fit(concat_simhash)  \n",
    "    indices = nbrs.kneighbors(concat_simhash,return_distance=False)\n",
    "    nbr_indices = indices[:, 1:]\n",
    "\n",
    "    for k in k_values:\n",
    "        graph = OverlapGraph.from_neighbor_indices(\n",
    "            neighbor_indices=nbr_indices,\n",
    "            n_neighbors=k,\n",
    "            read_ids=read_ids,\n",
    "            require_mutual_neighbors=False,\n",
    "        )\n",
    "        graphs[k] = graph\n",
    "\n",
    "    df_rows = []\n",
    "    for k in k_values:\n",
    "        graph = graphs[k]\n",
    "        graph_stats = get_overlap_statistics(query_graph=graph, reference_graph=reference_graph)\n",
    "        stats = { \"n_neighbors\": k}\n",
    "        stats = {\"description\":'SimHash', \"n_neighbors\": k, \"repeat_time\": repeat,\n",
    "                    **graph_stats}\n",
    "        df_rows.append(stats)\n",
    "    df = pd.DataFrame(df_rows)\n",
    "    dfs.append(df)\n",
    "    \n",
    "new = pd.concat(dfs)\n",
    "new.to_csv('/home/miaocj/docker_dir/test_simhash.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_table(tsv_path).iloc[:MAX_SAMPLE_SIZE, :].reset_index()\n",
    "read_indices = {read_name: read_id for read_id, read_name in meta_df['read_name'].items()}\n",
    "feature_matrix = sp.sparse.load_npz(npz_path)[meta_df.index, :]\n",
    "\n",
    "with gzip.open(json_path, \"rt\") as f:\n",
    "    read_features = json.load(f)\n",
    "    read_features = {i: read_features[i] for i in meta_df.index}\n",
    "\n",
    "feature_weights = {i: 1 for i in range(feature_matrix.shape[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_ids = np.array(list(read_features))\n",
    "graphs = collections.defaultdict(dict)\n",
    "k_values = np.arange(2, max_n_neighbors + 1)\n",
    "\n",
    "for k in k_values:\n",
    "    graph = OverlapGraph.from_neighbor_indices(\n",
    "        neighbor_indices=nbr_indices,\n",
    "        n_neighbors=k,\n",
    "        read_ids=read_ids,\n",
    "        require_mutual_neighbors=False,\n",
    "    )\n",
    "    graphs[k] = graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rows = []\n",
    "\n",
    "for k in k_values:\n",
    "    graph = graphs[k]\n",
    "    graph_stats = get_overlap_statistics(query_graph=graph, reference_graph=reference_graph)\n",
    "    stats = { \"n_neighbors\": k}\n",
    "    stats = {\"description\":'SimHash', \"n_neighbors\": k, \n",
    "                 **graph_stats}\n",
    "    df_rows.append(stats)\n",
    "df = pd.DataFrame(df_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##70\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##40\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##20\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试hash方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def simhash(features):\n",
    "  \n",
    "  # Generate a hash for each feature\n",
    "  hashes = [hashlib.sha1(feature).hexdigest() for feature in features]\n",
    "  \n",
    "  # Combine the feature hashes to produce the final simhash\n",
    "  concatenated_hash = ''.join(hashes)\n",
    "  simhash = hashlib.sha1(concatenated_hash).hexdigest()\n",
    "  \n",
    "  return simhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xxhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xxhash\n",
    "x = np.random.rand(1024 * 1024 * 16)\n",
    "h = xxhash.xxh64()\n",
    "h.update(x); h.intdigest(); h.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 64位， 40个repeat\n",
    "import numpy as np  \n",
    "import collections  \n",
    "from typing import Mapping  \n",
    "from sklearn.neighbors import NearestNeighbors  \n",
    "from scipy.spatial.distance import hamming  \n",
    "import mmh3  \n",
    "\n",
    "def _hash(kmer_index: int, seed: int) -> np.ndarray:  \n",
    "    hash_value = mmh3.hash(str(kmer_index), seed=seed)  \n",
    "    binary_string = \"{0:064b}\".format(hash_value & 0xFFFFFFFFFFFFFFFF)\n",
    "    hash_array = np.array([int(x) for x in binary_string], dtype=np.int32)  \n",
    "    return hash_array  \n",
    "\n",
    "def _get_simhash(  \n",
    "    read_features: list,  \n",
    "    feature_matrix: list,   \n",
    "    repeat: int,   \n",
    "    seed: int) -> Mapping[int,list]:  \n",
    "      \n",
    "    rng = np.random.default_rng(seed)  \n",
    "    hash_seeds = rng.integers(low=0, high=2**32 - 1, size=repeat, dtype=np.uint64)  \n",
    "  \n",
    "    repeat_all_read_hash = []  \n",
    "    for s in hash_seeds:  \n",
    "        print(s)\n",
    "        kmer_hash_indice = {}  \n",
    "        for kmer_index in range(feature_matrix.shape[1]):  \n",
    "            kmer_index_str = str(kmer_index)  \n",
    "            hash_list = _hash(kmer_index_str, seed=s)  \n",
    "            kmer_hash_indice[kmer_index] = hash_list  \n",
    "  \n",
    "        all_read_simhash = []  \n",
    "        for features in read_features.values():  \n",
    "            feature_count = dict(collections.Counter(features))  \n",
    "            one_read_hash = []  \n",
    "            for indice, count in feature_count.items():  \n",
    "                hash_list = kmer_hash_indice[indice]\n",
    "                hash_list = np.where(hash_list == 0, -1, hash_list) \n",
    "                weighted_hash_list = hash_list * count  \n",
    "                one_read_hash.append(weighted_hash_list)  \n",
    "            one_read_hash_array = np.array(one_read_hash)  \n",
    "            hash_sum = np.sum(one_read_hash_array, axis=0)   \n",
    "            simhash_value = np.where(hash_sum > 0, 1, 0)  \n",
    "            all_read_simhash.append(simhash_value)  \n",
    "  \n",
    "        repeat_all_read_hash.append(all_read_simhash)  \n",
    "  \n",
    "    concat_simhash = np.concatenate(repeat_all_read_hash, axis=1)  \n",
    "  \n",
    "    return concat_simhash \n",
    "\n",
    "concat_simhash = _get_simhash(read_features,feature_matrix,repeat = 40, seed = 4829)\n",
    "def hamming_distance(x, y):  \n",
    "    return np.count_nonzero(x != y)\n",
    "nbrs = NearestNeighbors(n_neighbors=21, algorithm='auto', metric=hamming_distance)\n",
    "nbrs.fit(concat_simhash)  \n",
    "indices = nbrs.kneighbors(concat_simhash,return_distance=False)\n",
    "nbr_indices = indices[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "beta = rng.uniform(0, 1, (feature_count, dimension_count))\n",
    "x = rng.uniform(0, 1, (feature_count, dimension_count))\n",
    "u1 = rng.uniform(0, 1, (feature_count, dimension_count))\n",
    "u2 = rng.uniform(0, 1, (feature_count, dimension_count))\n",
    "\n",
    "for j_sample in range(0, sample_count):\n",
    "    feature_indices = sparse.find(data[:, j_sample] > 0)[0]\n",
    "    gamma = -np.log(np.multiply(u1[feature_indices, :], u2[feature_indices, :]))\n",
    "    t_matrix = np.floor(\n",
    "        np.divide(\n",
    "            matlib.repmat(\n",
    "                np.log(data[feature_indices, j_sample].todense()),\n",
    "                1,\n",
    "                dimension_count,\n",
    "            ),\n",
    "            gamma,\n",
    "        )\n",
    "        + beta[feature_indices, :]\n",
    "    )\n",
    "    y_matrix = np.exp(np.multiply(gamma, t_matrix - beta[feature_indices, :]))\n",
    "    a_matrix = np.divide(\n",
    "        -np.log(x[feature_indices, :]),\n",
    "        np.divide(y_matrix, u1[feature_indices, :]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##建立hash矩阵\n",
    "import numpy as np  \n",
    "import collections  \n",
    "from typing import Mapping  \n",
    "from sklearn.neighbors import NearestNeighbors  \n",
    "from scipy.spatial.distance import hamming  \n",
    "import mmh3  \n",
    "\n",
    "def _hash(kmer_index: int, seed: int) -> np.ndarray:  \n",
    "    hash_value = mmh3.hash(str(kmer_index), seed=seed)  \n",
    "    binary_string = \"{0:032b}\".format(hash_value & 0xFFFFFFFF)  \n",
    "    hash_array = np.array([int(x) for x in binary_string], dtype=np.int32)  \n",
    "    return hash_array  \n",
    "\n",
    "def _get_simhash(  \n",
    "    read_features: list,  \n",
    "    feature_matrix: list,   \n",
    "    repeat: int,   \n",
    "    seed: int) -> Mapping[int,list]:  \n",
    "      \n",
    "    rng = np.random.default_rng(seed)  \n",
    "    hash_seeds = rng.integers(low=0, high=2**32 - 1, size=repeat, dtype=np.uint64)  \n",
    "  \n",
    "    repeat_all_read_hash = []  \n",
    "    hash_table = np.empty((repeat,feature_matrix.shape[1]))  \n",
    "    for s in hash_seeds:  \n",
    "        print(s)\n",
    "        kmer_hash_indice = {}  \n",
    "        for kmer_index in range(feature_matrix.shape[1]): \n",
    "            hash_table[s,kmer_index] = _hash(kmer_index, seed=s)\n",
    "    for \n",
    "         \n",
    "        all_read_simhash = []  \n",
    "        for features in read_features.values():  \n",
    "            feature_count = dict(collections.Counter(features))  \n",
    "            one_read_hash = []  \n",
    "            for indice, count in feature_count.items():  \n",
    "                hash_list = kmer_hash_indice[indice]\n",
    "                hash_list = np.where(hash_list == 0, -1, hash_list) \n",
    "                weighted_hash_list = hash_list * count  \n",
    "                one_read_hash.append(weighted_hash_list)  \n",
    "            one_read_hash_array = np.array(one_read_hash)  \n",
    "            hash_sum = np.sum(one_read_hash_array, axis=0)   \n",
    "            simhash_value = np.where(hash_sum > 0, 1, 0)  \n",
    "            all_read_simhash.append(simhash_value)  \n",
    "  \n",
    "        repeat_all_read_hash.append(all_read_simhash)  \n",
    "  \n",
    "    concat_simhash = np.concatenate(repeat_all_read_hash, axis=1)  \n",
    "  \n",
    "    return concat_simhash \n",
    "\n",
    "concat_simhash = _get_simhash(read_features,feature_matrix,repeat = 70, seed = 4829)\n",
    "def hamming_distance(x, y):  \n",
    "    return np.count_nonzero(x != y)\n",
    "nbrs = NearestNeighbors(n_neighbors=21, algorithm='auto', metric=hamming_distance)\n",
    "nbrs.fit(concat_simhash)  \n",
    "indices = nbrs.kneighbors(concat_simhash,return_distance=False)\n",
    "nbr_indices = indices[:, 1:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
