{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading done\n",
      "building kmer index\n",
      "Counter({2: 66553881, 4: 7903925, 1: 2368196, 6: 974758, 8: 273618, 3: 213990, 10: 57248, 5: 55512, 7: 16132, 9: 5414})\n",
      "done\n",
      "loading query reads\n",
      "done\n",
      "building feature matrix\n",
      "done\n",
      "building hash table\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/4262b1bf4bf1ffb403c0eb7a42ad5906_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/4506eccf78279d93d0e8a34c035e91c5_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/6bda807e3967eae797c7b1b9eeaee8db_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/c2a47d89d1d34e789fdf782557bb7194_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/c6c5514ada15b890fb27d1e36371554c_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/d964a294c2d0fef56a434c021026281e_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/e1c932db5cd4271709e54d8028824bc9_/lib/python3.12/site-packages\")\n",
    "\n",
    "from typing import TYPE_CHECKING\n",
    "if TYPE_CHECKING:\n",
    "    from snakemake_stub import *\n",
    "from Bio import SeqIO\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors  \n",
    "import numpy as np\n",
    "from sim_meta_function import load_reads,build_kmer_index,build_feature_matrix,get_table,get_simhash,evaluate\n",
    "\n",
    "ref_database = '/home/miaocj/docker_dir/data/metagenome/bacteria/part1.fa'\n",
    "query_reads = '/home/miaocj/docker_dir/data/metagenome/bacteria/pbsim_ONT_98_30k_10dep_part1_reads.fasta'\n",
    "\n",
    "def init_reverse_complement():\n",
    "    TRANSLATION_TABLE = str.maketrans(\"ACTGactg\", \"TGACtgac\")\n",
    "\n",
    "    def reverse_complement(sequence: str) -> str:\n",
    "        \"\"\"\n",
    "        >>> reverse_complement(\"AATC\")\n",
    "        'GATT'\n",
    "        >>> reverse_complement(\"CCANT\")\n",
    "        'ANTGG'\n",
    "        \"\"\"\n",
    "        sequence = str(sequence)\n",
    "        return sequence.translate(TRANSLATION_TABLE)[::-1]\n",
    "\n",
    "    return reverse_complement\n",
    "reverse_complement = init_reverse_complement()\n",
    "\n",
    "k=100000\n",
    "split_ref = []\n",
    "ref_reads_tax_list = []\n",
    "with open(ref_database, \"rt\") as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        tax=record.description.split(' ')[1]+record.description.split(' ')[2]\n",
    "        for p in range(0,len(record.seq) - k + 1,50000):\n",
    "            kmer = record.seq[p : p + k]\n",
    "            split_ref.append(kmer)\n",
    "            ref_reads_tax_list.append(tax)\n",
    "            split_ref.append(reverse_complement(kmer))\n",
    "split_ref_tax_dict = {i:tax for i,tax in enumerate(ref_reads_tax_list)}\n",
    "\n",
    "ref_reads_tax_list = []\n",
    "with open(ref_database) as file:\n",
    "    for lines in file:\n",
    "        if lines[0] == '>':\n",
    "            line = lines.strip().split(' ')\n",
    "            ref_reads_tax_list.append(line[1]+line[2])\n",
    "ref_read_tax = {i:tax for i,tax in enumerate(ref_reads_tax_list)}\n",
    "\n",
    "flag = 0\n",
    "que_read_tax = {}\n",
    "with open(query_reads) as file:\n",
    "    for lines in file:\n",
    "        if lines[0] == '>':\n",
    "            start = lines.index('S')\n",
    "            end = lines.index('_')\n",
    "            ref_num = lines[start+1:end]\n",
    "            que_read_tax[flag] = ref_read_tax[int(ref_num)-1]\n",
    "            flag +=1\n",
    "print(\"loading done\\nbuilding kmer index\")\n",
    "sample_fraction=0.1\n",
    "min_multiplicity=2\n",
    "seed=562104830\n",
    "kmer_indices = build_kmer_index(\n",
    "        read_sequences=split_ref,\n",
    "        k=16,\n",
    "        sample_fraction=sample_fraction,\n",
    "        min_multiplicity=min_multiplicity,\n",
    "        seed=seed)\n",
    "print(\"done\\nloading query reads\")\n",
    "qread_names, qread_orientations, qread_sequences = load_reads(query_reads)\n",
    "\n",
    "print(\"done\\nbuilding feature matrix\")\n",
    "\n",
    "ref_feature_matrix,ref_read_features = build_feature_matrix(read_sequences=split_ref,kmer_indices=kmer_indices,k=16)\n",
    "que_feature_matrix,que_read_features = build_feature_matrix(read_sequences=qread_sequences,kmer_indices=kmer_indices,k=16)\n",
    "kmer_num = que_feature_matrix.shape[1]\n",
    "print(\"done\\nbuilding hash table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1804, 14482315)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "get ref simhash\n",
      "ref done\n",
      "get que simhash\n",
      "que done\n",
      "get neignbors\n",
      "done\n",
      "evaluates\n",
      "0.9898351069527734 0.9895657254201538 [0.9885103  0.99408721 0.99716178 0.97678221 0.99534247 0.99420443\n",
      " 0.98779637 0.98921569 0.99586777 0.97588832 0.99332963] [0.99720224 0.9962963  0.99246704 0.97806156 0.97871767 0.98589342\n",
      " 0.99683322 0.9990099  0.9790625  0.98779705 0.99388209]\n"
     ]
    }
   ],
   "source": [
    "# repeat=60\n",
    "# new = np.load('/home/miaocj/docker_dir/data/metagenome/hash_table.npz')\n",
    "# hash_table_bool = new['arr_0'][:kmer_num]\n",
    "# hash_table2 = hash_table_bool.astype(int)  \n",
    "# hash_table = np.where(hash_table2 == 0, -1, 1)\n",
    "\n",
    "print(\"done\\nget ref simhash\")\n",
    "ref_reads_simhash_array = get_simhash(ref_read_features,hash_table)\n",
    "print(\"ref done\\nget que simhash\")\n",
    "que_reads_simhash_array = get_simhash(que_read_features,hash_table) ##修改simhash的计算 去掉concate\n",
    "print(\"que done\\nget neignbors\")\n",
    "def hamming_distance(x, y):\n",
    "    return np.count_nonzero(x != y)\n",
    "nbrs = NearestNeighbors(n_neighbors=1, algorithm='auto', metric=hamming_distance)\n",
    "nbrs.fit(ref_reads_simhash_array)\n",
    "indices = nbrs.kneighbors(que_reads_simhash_array,return_distance=False)\n",
    "print(\"done\\nevaluates\")\n",
    "\n",
    "##evaluate\n",
    "precision,sensitivity,precision_sep,sensitivity_sep = evaluate(indices,split_ref_tax_dict,que_read_tax)\n",
    "print(precision,sensitivity,precision_sep,sensitivity_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99720224, 0.9962963 , 0.99246704, 0.97806156, 0.97871767,\n",
       "       0.98589342, 0.99683322, 0.9990099 , 0.9790625 , 0.98779705,\n",
       "       0.99388209])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer_num = que_feature_matrix.shape[1]\n",
    "new = np.load('/home/miaocj/docker_dir/data/metagenome/hash_table.npz')\n",
    "hash_table_bool = new['arr_0'][:kmer_num]\n",
    "hash_table2 = hash_table_bool.astype('int8')  \n",
    "hash_table = np.where(hash_table2 == 0, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_table_bool.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref done\n",
      "get que simhash\n",
      "que done\n",
      "get neignbors\n",
      "done\n",
      "evaluates\n",
      "0.9981726870494413 0.9985136609918157 [0.9988024  0.99925981 1.         0.99478827 1.         0.99739448\n",
      " 0.99754213 0.9967925  0.99843994 0.9974359  0.99944414] [1.         1.         1.         1.         0.9846444  1.\n",
      " 0.99964814 1.         1.         0.99935774 1.        ]\n"
     ]
    }
   ],
   "source": [
    "ref_reads_simhash_array = get_simhash(ref_read_features,hash_array)\n",
    "print(\"ref done\\nget que simhash\")\n",
    "que_reads_simhash_array = get_simhash(que_read_features,hash_array) ##修改simhash的计算 去掉concate\n",
    "\n",
    "print(\"que done\\nget neignbors\")\n",
    "def hamming_distance(x, y):\n",
    "    return np.count_nonzero(x != y)\n",
    "nbrs = NearestNeighbors(n_neighbors=1, algorithm='auto', metric=hamming_distance)\n",
    "nbrs.fit(ref_reads_simhash_array)\n",
    "indices = nbrs.kneighbors(que_reads_simhash_array,return_distance=False)\n",
    "print(\"done\\nevaluates\")\n",
    "\n",
    "##evaluate\n",
    "precision,sensitivity,precision_sep,sensitivity_sep = evaluate(indices,split_ref_tax_dict,que_read_tax)\n",
    "print(precision,sensitivity,precision_sep,sensitivity_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('/home/miaocj/docker_dir/data/metagenome/hash_table.npz',hash_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree', metric=hamming_distance)\n",
    "nbrs.fit(ref_reads_simhash_array)\n",
    "indices = nbrs.kneighbors(que_reads_simhash_array,return_distance=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "4262b1bf4bf1ffb403c0eb7a42ad5906_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
