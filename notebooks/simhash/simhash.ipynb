{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##version1\n",
    "def _hash(kmer_index: int, seed: int) -> np.ndarray:  \n",
    "    hash_value = mmh3.hash(str(kmer_index), seed=seed)\n",
    "    binary_string = \"{0:032b}\".format(hash_value & 0xFFFFFFFF)  \n",
    "    hash_array = np.array([int(x) for x in binary_string], dtype=np.int32) \n",
    "    hash_array = np.where(hash_array == 0, -1, 1)  \n",
    "    return hash_array  \n",
    "\n",
    "def _get_simhash(  \n",
    "    read_features: list,  \n",
    "    feature_matrix: list,   \n",
    "    repeat: int,   \n",
    "    seed: int) -> Mapping[int,list]:  \n",
    "      \n",
    "    rng = np.random.default_rng(seed)  \n",
    "    hash_seeds = rng.integers(low=0, high=2**32 - 1, size=repeat, dtype=np.uint64)  \n",
    "  \n",
    "    all_read_simhash = []\n",
    "    kmer_num = feature_matrix.shape[1]\n",
    "    hash_table = np.empty((kmer_num,repeat),dtype=object)  \n",
    "    for flag,seed in enumerate(hash_seeds):\n",
    "        kmer_hash_indice = {} \n",
    "        for kmer_index in range(kmer_num):\n",
    "            hash_table[kmer_index,flag]=_hash(kmer_index, seed=seed)\n",
    "\n",
    "    for read_ind,read_kmer in read_features.items():\n",
    "        one_read_hash = np.sum(hash_table[read_kmer,:],axis=0)\n",
    "        conc_hash = np.concatenate(one_read_hash)\n",
    "        simhash = np.where(conc_hash > 0, 1, 0)\n",
    "        all_read_simhash.append(simhash)\n",
    "    reads_simhash_array = np.array(all_read_simhash)\n",
    "  \n",
    "    return reads_simhash_array \n",
    "\n",
    "def hamming_distance(x, y):  \n",
    "    return np.count_nonzero(x != y)\n",
    "\n",
    "for repeat in range(50,110,10):\n",
    "    print(repeat)\n",
    "    concat_simhash = _get_simhash(read_features,feature_matrix,repeat =repeat, seed = 4829)\n",
    "    nbrs = NearestNeighbors(n_neighbors=21, algorithm='auto', metric=hamming_distance)\n",
    "    nbrs.fit(concat_simhash)  \n",
    "    indices = nbrs.kneighbors(concat_simhash,return_distance=False)\n",
    "    nbr_indices = indices[:, 1:]\n",
    "\n",
    "    for k in k_values:\n",
    "        graph = OverlapGraph.from_neighbor_indices(\n",
    "            neighbor_indices=nbr_indices,\n",
    "            n_neighbors=k,\n",
    "            read_ids=read_ids,\n",
    "            require_mutual_neighbors=False,\n",
    "        )\n",
    "        graph_stats = get_overlap_statistics(query_graph=graph, reference_graph=reference_graph)\n",
    "        stats = { \"n_neighbors\": k}\n",
    "        stats = {\"description\":'SimHash', \"n_neighbors\": k, \"repeat_time\": repeat,\n",
    "                    **graph_stats}\n",
    "        df_rows.append(stats)\n",
    "    df = pd.DataFrame(df_rows)\n",
    "    dfs.append(df)\n",
    "\n",
    "new = pd.concat(dfs)\n",
    "new.to_csv('/home/miaocj/docker_dir/test_simhash.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##version2 numpy calculate hash values\n",
    "##需要整合成函数\n",
    "repeat = 20\n",
    "\n",
    "hash_seeds = np.array(range(repeat))\n",
    "kmer_num = feature_matrix.shape[1]\n",
    "kmer_index = np.array(range(kmer_num))\n",
    "\n",
    "table = []\n",
    "for seed in hash_seeds:\n",
    "    prime1 = 2654435761  # A large prime number\n",
    "    prime2 = 0x27d4eb2d  # Another large prime, often used in hashing\n",
    "    hash_value = (kmer_index * prime1) ^ (seed * prime2)\n",
    "    hash_t = hash_value % (2**32)\n",
    "    binary_matrix = np.vectorize(np.binary_repr)(hash_t, width=32)\n",
    "    one_repear_table = np.array([list(row) for row in binary_matrix.flatten()])\n",
    "    table.append(one_repear_table.astype(int))\n",
    "\n",
    "table = np.where(table ==0,-1,1)\n",
    "hash_table1 = np.hstack(table)\n",
    "print(\"hash_Table1 es\")\n",
    "hash_table = np.where(hash_table1 ==0,-1,1)\n",
    "print(\"hash_table established\")\n",
    "\n",
    "all_read_simhash = []\n",
    "\n",
    "for read_ind,read_kmer in read_features.items():\n",
    "    one_read_hash = np.sum(hash_table[read_kmer,:],axis=0)\n",
    "    simhash = np.where(conc_hash > 0, 1, 0)\n",
    "    all_read_simhash.append(simhash)\n",
    "reads_simhash_array = np.array(all_read_simhash)\n",
    "\n",
    "\n",
    "for repeat in range(50,110,10):\n",
    "    print(repeat)\n",
    "    concat_simhash = _get_simhash(read_features,feature_matrix,repeat =repeat, seed = 4829)\n",
    "    nbrs = NearestNeighbors(n_neighbors=21, algorithm='auto', metric=hamming_distance)\n",
    "    nbrs.fit(concat_simhash)  \n",
    "    indices = nbrs.kneighbors(concat_simhash,return_distance=False)\n",
    "    nbr_indices = indices[:, 1:]\n",
    "\n",
    "    for k in k_values:\n",
    "        graph = OverlapGraph.from_neighbor_indices(\n",
    "            neighbor_indices=nbr_indices,\n",
    "            n_neighbors=k,\n",
    "            read_ids=read_ids,\n",
    "            require_mutual_neighbors=False,\n",
    "        )\n",
    "        graph_stats = get_overlap_statistics(query_graph=graph, reference_graph=reference_graph)\n",
    "        stats = { \"n_neighbors\": k}\n",
    "        stats = {\"description\":'SimHash', \"n_neighbors\": k, \"repeat_time\": repeat,\n",
    "                    **graph_stats}\n",
    "        df_rows.append(stats)\n",
    "    df = pd.DataFrame(df_rows)\n",
    "    dfs.append(df)\n",
    "\n",
    "new = pd.concat(dfs)\n",
    "new.to_csv('/home/miaocj/docker_dir/test_simhash.csv',sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
