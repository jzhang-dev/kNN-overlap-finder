{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/conda/pkgs')\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/4262b1bf4bf1ffb403c0eb7a42ad5906_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/4506eccf78279d93d0e8a34c035e91c5_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/6bda807e3967eae797c7b1b9eeaee8db_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/c2a47d89d1d34e789fdf782557bb7194_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/c6c5514ada15b890fb27d1e36371554c_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/d964a294c2d0fef56a434c021026281e_/lib/python3.12/site-packages\")\n",
    "sys.path.append(\"/home/miaocj/docker_dir/kNN-overlap-finder/.snakemake/conda/e1c932db5cd4271709e54d8028824bc9_/lib/python3.12/site-packages\")\n",
    "import gzip, json\n",
    "from Bio import SeqIO\n",
    "import scipy.sparse as sp\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "fasta_gz_file = '/home/miaocj/docker_dir/kNN-overlap-finder/data/regional_reads/Ecoli/all/ONT/reads.fasta.gz'\n",
    "paf_gz_file = '/home/miaocj/docker_dir/kNN-overlap-finder/data/regional_reads/Ecoli/all/ONT/alignment.paf.gz'\n",
    "with gzip.open(paf_gz_file, \"rt\") as file:\n",
    "    max_values = {}  \n",
    "    for row in file:  \n",
    "        columns = row.strip().split('\\t') \n",
    "        query_id = columns[0]  \n",
    "        match_bases = int(columns[9]) \n",
    "        max_values[query_id] = columns \n",
    "        if query_id in max_values:  \n",
    "            if match_bases > int(max_values[query_id][9]):  \n",
    "                max_values[match_bases] = columns\n",
    "        else:  \n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle, os, gzip, json, sys, itertools\n",
    "from pathlib import Path\n",
    "from importlib import reload\n",
    "from dataclasses import dataclass, field\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysam\n",
    "import scipy as sp\n",
    "from typing import Mapping  \n",
    "import mmh3\n",
    "from itertools import chain  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/miaocj/docker_dir/kNN-overlap-finder/scripts/../lib\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"scripts\")\n",
    "sys.path.append(\"../../scripts\")\n",
    "from data_io import is_fwd_id, get_fwd_id, get_sibling_id\n",
    "from graph import OverlapGraph, GenomicInterval, get_overlap_statistics, remove_false_edges\n",
    "from nearest_neighbors import SimHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import collections  \n",
    "from typing import Mapping  \n",
    "from sklearn.neighbors import NearestNeighbors  \n",
    "from scipy.spatial.distance import hamming  \n",
    "import mmh3  \n",
    "max_n_neighbors = 20\n",
    "k_values = np.arange(2, max_n_neighbors + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import profile\n",
    "%load_ext memory_profiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 533.75 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit x = 10+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9493518828919433\n",
      "0.9829031176667784\n"
     ]
    }
   ],
   "source": [
    "MAX_SAMPLE_SIZE = int(1e9)\n",
    "COVERAGE_DEPTH = 20\n",
    "max_n_neighbors = 20\n",
    "with gzip.open(fasta_gz_file, \"rt\") as handle:\n",
    "    flag = 0\n",
    "    seq_num = 0\n",
    "    aligned_num = 0\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        seq_num += 1\n",
    "        if record.id in max_values.keys():\n",
    "            aligned_num+=1\n",
    "            columns = max_values[record.id]\n",
    "            if int(columns[9])/int(columns[1]) > 0.5:\n",
    "                flag += 1\n",
    "    print(flag/seq_num)\n",
    "    print(aligned_num/seq_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_path = \"/home/miaocj/docker_dir/kNN-overlap-finder/data/feature_matrix/CHM13/IGK/pbsim_ONT_93_30k/kmer_k16/feature_matrix.npz\"\n",
    "tsv_path = \"/home/miaocj/docker_dir/kNN-overlap-finder/data/feature_matrix/CHM13/IGK/pbsim_ONT_93_30k//kmer_k16/metadata.tsv.gz\"\n",
    "json_path = \"/home/miaocj/docker_dir/kNN-overlap-finder/data/feature_matrix/CHM13/IGK/pbsim_ONT_93_30k/kmer_k16/read_features.json.gz\"\n",
    "\n",
    "meta_df = pd.read_table(tsv_path).iloc[:MAX_SAMPLE_SIZE, :].reset_index()\n",
    "read_indices = {read_name: read_id for read_id, read_name in meta_df['read_name'].items()}\n",
    "feature_matrix = sp.sparse.load_npz(npz_path)[meta_df.index, :]\n",
    "\n",
    "with gzip.open(json_path, \"rt\") as f:\n",
    "    read_features = json.load(f)\n",
    "    read_features = {i: read_features[i] for i in meta_df.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5106, 103266, 9866, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_read_intervals(meta_df):\n",
    "    read_intervals = {\n",
    "        i: [GenomicInterval(strand, start, end)]\n",
    "        for i, strand, start, end in zip(\n",
    "            meta_df.index,\n",
    "            meta_df[\"reference_strand\"],\n",
    "            meta_df[\"reference_start\"],\n",
    "            meta_df[\"reference_end\"],\n",
    "        )\n",
    "    }\n",
    "    return read_intervals\n",
    "\n",
    "read_intervals = get_read_intervals(meta_df)\n",
    "\n",
    "reference_graph = OverlapGraph.from_intervals(read_intervals)\n",
    "nr_edges = set((node_1, node_2) for node_1, node_2, data in reference_graph.edges(data=True) if not data['redundant'])\n",
    "connected_component_count = len(list(nx.connected_components(reference_graph)))\n",
    "len(reference_graph.nodes), len(reference_graph.edges), len(nr_edges), connected_component_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_indices = SimHash().get_neighbors(feature_matrix,read_features,20,tf=True,idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_ids = np.array(list(read_features))\n",
    "graph = OverlapGraph.from_neighbor_indices(\n",
    "    neighbor_indices=nbr_indices,\n",
    "    n_neighbors=6,\n",
    "    read_ids=read_ids,\n",
    "    require_mutual_neighbors=False,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_small_components(graph, min_component_size=10):\n",
    "    small_components = set()\n",
    "    for component in nx.connected_components(graph):\n",
    "        if len(component) < min_component_size:\n",
    "            small_components |= component\n",
    "    graph.remove_nodes_from(small_components)\n",
    "            \n",
    "    \n",
    "def plot_graphs(graphs, reference_graph, metadata, *, min_component_size=10, \n",
    "                processes=8, layout_method='stdp', figsize=(6, 6), node_size=3,\n",
    "    seed: int = 4829, verbose=True):\n",
    "    axes = []\n",
    "    new_graphs = []\n",
    "    g = graphs\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), constrained_layout=True)\n",
    "    ax1.set_title(\"All edges\")\n",
    "    ax2.set_title(\"Correct edges\")\n",
    "    \n",
    "    g = g.copy()\n",
    "    remove_small_components(g, min_component_size=min_component_size)\n",
    "    new_graphs.append(g)\n",
    "    axes.append(ax1)\n",
    "\n",
    "    g = g.copy()\n",
    "    remove_false_edges(g, reference_graph)\n",
    "    remove_small_components(g, min_component_size=min_component_size)\n",
    "    new_graphs.append(g)\n",
    "    axes.append(ax2)\n",
    "\n",
    "    fig.suptitle('method', ha=\"center\", va=\"bottom\", wrap=True, size=7)\n",
    "\n",
    "    query_graphs = new_graphs\n",
    "    def plot(i, pos):\n",
    "        plot_read_graph(\n",
    "            ax=axes[i],\n",
    "            query_graph=query_graphs[i],\n",
    "            reference_graph=reference_graph,\n",
    "            metadata=metadata,\n",
    "            pos=pos,\n",
    "            node_size=node_size,\n",
    "        )\n",
    "\n",
    "    with sharedmem.MapReduce(np=processes) as pool:\n",
    "\n",
    "        def work(i):\n",
    "            if layout_method == \"umap\":\n",
    "                pos = get_umap_layout(graph=query_graphs[i])\n",
    "            else:\n",
    "                pos = get_graphviz_layout(\n",
    "                    graph=query_graphs[i],\n",
    "                    figsize=figsize,\n",
    "                    seed=seed,\n",
    "                    layout_method=layout_method,\n",
    "                )\n",
    "            return i, pos\n",
    "\n",
    "        def reduce(i, pos):\n",
    "            if verbose:\n",
    "                print(i, end=\" \")\n",
    "            plot(i, pos)\n",
    "\n",
    "        pool.map(work, range(len(query_graphs)), reduce=reduce)\n",
    "        if verbose:\n",
    "            print(\"\")\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hash(kmer_index: int, seed: int) -> np.ndarray:  \n",
    "    hash_value = mmh3.hash(str(kmer_index), seed=seed)\n",
    "    binary_string = \"{0:032b}\".format(hash_value & 0xFFFFFFFF)  \n",
    "    hash_array = np.array([int(x) for x in binary_string], dtype=np.int32) \n",
    "    hash_array = np.where(hash_array == 0, -1, 1)  \n",
    "    return hash_array  \n",
    "\n",
    "def _get_simhash(  \n",
    "    read_features: list,  \n",
    "    feature_matrix: list,   \n",
    "    repeat: int,   \n",
    "    seed: int) -> Mapping[int,list]:  \n",
    "      \n",
    "    rng = np.random.default_rng(seed)  \n",
    "    hash_seeds = rng.integers(low=0, high=2**32 - 1, size=repeat, dtype=np.uint64)  \n",
    "  \n",
    "    all_read_simhash = []\n",
    "    kmer_num = feature_matrix.shape[1]\n",
    "    hash_table = np.empty((kmer_num,repeat),dtype=object)  \n",
    "    for flag,seed in enumerate(hash_seeds):\n",
    "        for kmer_index in range(kmer_num):\n",
    "            hash_table[kmer_index,flag]=_hash(kmer_index, seed=seed)\n",
    "\n",
    "    for read_kmer in read_features.keys():\n",
    "        one_read_hash = np.sum(hash_table[read_kmer,:],axis=0)\n",
    "        conc_hash = np.concatenate(one_read_hash)\n",
    "        simhash = np.where(conc_hash > 0, 1, 0)\n",
    "        all_read_simhash.append(simhash)\n",
    "    reads_simhash_array = np.array(all_read_simhash)\n",
    "  \n",
    "    return reads_simhash_array \n",
    "\n",
    "def hamming_distance(x, y):  \n",
    "    return np.count_nonzero(x != y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "90\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import collections  \n",
    "from typing import Mapping  \n",
    "from sklearn.neighbors import NearestNeighbors  \n",
    "from scipy.spatial.distance import hamming  \n",
    "import mmh3  \n",
    "\n",
    "for repeat in [100]:\n",
    "    print(repeat)\n",
    "    concat_simhash = _get_simhash(read_features,feature_matrix,repeat =repeat, seed = 4829)\n",
    "    nbrs = NearestNeighbors(n_neighbors=21, algorithm='auto', metric=hamming_distance)\n",
    "    nbrs.fit(concat_simhash)  \n",
    "    indices = nbrs.kneighbors(concat_simhash,return_distance=False)\n",
    "    nbr_indices = indices[:, 1:]\n",
    "\n",
    "    for k in k_values:\n",
    "        graph = OverlapGraph.from_neighbor_indices(\n",
    "            neighbor_indices=nbr_indices,\n",
    "            n_neighbors=k,\n",
    "            read_ids=read_ids,\n",
    "            require_mutual_neighbors=False,\n",
    "        )\n",
    "        graph_stats = get_overlap_statistics(query_graph=graph, reference_graph=reference_graph)\n",
    "        stats = { \"n_neighbors\": k}\n",
    "        stats = {\"description\":'SimHash', \"n_neighbors\": k, \"repeat_time\": repeat,\n",
    "                    **graph_stats}\n",
    "        df_rows.append(stats)\n",
    "    df = pd.DataFrame(df_rows)\n",
    "    dfs.append(df)\n",
    "\n",
    "new = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>description</th>\n",
       "      <th>n_neighbors</th>\n",
       "      <th>repeat_time</th>\n",
       "      <th>precision</th>\n",
       "      <th>nr_precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>nr_recall</th>\n",
       "      <th>singleton_count</th>\n",
       "      <th>singleton_fraction</th>\n",
       "      <th>N50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SimHash</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0.010583</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.003138</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>5100</td>\n",
       "      <td>0.998825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>SimHash</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.404492</td>\n",
       "      <td>0.093531</td>\n",
       "      <td>0.090165</td>\n",
       "      <td>0.218224</td>\n",
       "      <td>1299</td>\n",
       "      <td>0.254407</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>42</td>\n",
       "      <td>SimHash</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0.732396</td>\n",
       "      <td>0.190486</td>\n",
       "      <td>0.170414</td>\n",
       "      <td>0.463916</td>\n",
       "      <td>200</td>\n",
       "      <td>0.039170</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>61</td>\n",
       "      <td>SimHash</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0.733710</td>\n",
       "      <td>0.188656</td>\n",
       "      <td>0.170869</td>\n",
       "      <td>0.459862</td>\n",
       "      <td>212</td>\n",
       "      <td>0.041520</td>\n",
       "      <td>344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>SimHash</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0.732396</td>\n",
       "      <td>0.190486</td>\n",
       "      <td>0.170414</td>\n",
       "      <td>0.463916</td>\n",
       "      <td>200</td>\n",
       "      <td>0.039170</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>156</td>\n",
       "      <td>SimHash</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>0.768928</td>\n",
       "      <td>0.201489</td>\n",
       "      <td>0.179972</td>\n",
       "      <td>0.493614</td>\n",
       "      <td>139</td>\n",
       "      <td>0.027223</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>175</td>\n",
       "      <td>SimHash</td>\n",
       "      <td>6</td>\n",
       "      <td>70</td>\n",
       "      <td>0.770857</td>\n",
       "      <td>0.202796</td>\n",
       "      <td>0.180476</td>\n",
       "      <td>0.496959</td>\n",
       "      <td>138</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>194</td>\n",
       "      <td>SimHash</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>0.775372</td>\n",
       "      <td>0.204339</td>\n",
       "      <td>0.181705</td>\n",
       "      <td>0.501216</td>\n",
       "      <td>136</td>\n",
       "      <td>0.026635</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>213</td>\n",
       "      <td>SimHash</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>0.777328</td>\n",
       "      <td>0.204199</td>\n",
       "      <td>0.182141</td>\n",
       "      <td>0.500811</td>\n",
       "      <td>130</td>\n",
       "      <td>0.025460</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>232</td>\n",
       "      <td>SimHash</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>0.778751</td>\n",
       "      <td>0.205552</td>\n",
       "      <td>0.182558</td>\n",
       "      <td>0.504358</td>\n",
       "      <td>129</td>\n",
       "      <td>0.025264</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 description  n_neighbors  repeat_time  precision  \\\n",
       "4              4     SimHash            6           20   0.010583   \n",
       "23            23     SimHash            6            2   0.404492   \n",
       "42            42     SimHash            6           20   0.732396   \n",
       "61            61     SimHash            6           20   0.733710   \n",
       "80            80     SimHash            6           20   0.732396   \n",
       "...          ...         ...          ...          ...        ...   \n",
       "1448         156     SimHash            6           60   0.768928   \n",
       "1467         175     SimHash            6           70   0.770857   \n",
       "1486         194     SimHash            6           80   0.775372   \n",
       "1505         213     SimHash            6           90   0.777328   \n",
       "1524         232     SimHash            6          100   0.778751   \n",
       "\n",
       "      nr_precision    recall  nr_recall  singleton_count  singleton_fraction  \\\n",
       "4         0.000784  0.003138   0.002433             5100            0.998825   \n",
       "23        0.093531  0.090165   0.218224             1299            0.254407   \n",
       "42        0.190486  0.170414   0.463916              200            0.039170   \n",
       "61        0.188656  0.170869   0.459862              212            0.041520   \n",
       "80        0.190486  0.170414   0.463916              200            0.039170   \n",
       "...            ...       ...        ...              ...                 ...   \n",
       "1448      0.201489  0.179972   0.493614              139            0.027223   \n",
       "1467      0.202796  0.180476   0.496959              138            0.027027   \n",
       "1486      0.204339  0.181705   0.501216              136            0.026635   \n",
       "1505      0.204199  0.182141   0.500811              130            0.025460   \n",
       "1524      0.205552  0.182558   0.504358              129            0.025264   \n",
       "\n",
       "      N50  \n",
       "4       1  \n",
       "23     88  \n",
       "42    262  \n",
       "61    344  \n",
       "80    262  \n",
       "...   ...  \n",
       "1448  271  \n",
       "1467  270  \n",
       "1486  396  \n",
       "1505  400  \n",
       "1524  400  \n",
       "\n",
       "[81 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.n_neighbors==6 &]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nbrs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m indices \u001b[38;5;241m=\u001b[39m nbrs\u001b[38;5;241m.\u001b[39mkneighbors(concat_simhash,return_distance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m nbr_indices \u001b[38;5;241m=\u001b[39m indices[:, \u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nbrs' is not defined"
     ]
    }
   ],
   "source": [
    "indices = nbrs.kneighbors(concat_simhash,return_distance=False)\n",
    "nbr_indices = indices[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_values:\n",
    "    graph = OverlapGraph.from_neighbor_indices(\n",
    "        neighbor_indices=nbr_indices,\n",
    "        n_neighbors=k,\n",
    "        read_ids=read_ids,\n",
    "        require_mutual_neighbors=False,\n",
    "    )\n",
    "    graph_stats = get_overlap_statistics(query_graph=graph, reference_graph=reference_graph)\n",
    "    stats = { \"n_neighbors\": k}\n",
    "    stats = {\"description\":'SimHash', \"n_neighbors\": k, \"repeat_time\": repeat,\n",
    "                **graph_stats}\n",
    "    df_rows.append(stats)\n",
    "df = pd.DataFrame(df_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试hash方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def simhash(features):\n",
    "  \n",
    "  # Generate a hash for each feature\n",
    "  hashes = [hashlib.sha1(feature).hexdigest() for feature in features]\n",
    "  \n",
    "  # Combine the feature hashes to produce the final simhash\n",
    "  concatenated_hash = ''.join(hashes)\n",
    "  simhash = hashlib.sha1(concatenated_hash).hexdigest()\n",
    "  \n",
    "  return simhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xxhash\n",
      "  Downloading xxhash-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Downloading xxhash-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.3/194.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash\n",
      "Successfully installed xxhash-3.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xxhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xxhash\n",
    "x = np.random.rand(1024 * 1024 * 16)\n",
    "h = xxhash.xxh64()\n",
    "h.update(x); h.intdigest(); h.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29611066, 0.45210823, 0.21455805, ..., 0.22218214, 0.79713455,\n",
       "       0.43898445])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299897765\n",
      "2378963497\n",
      "44873935\n",
      "2670060064\n",
      "25935175\n",
      "920060685\n",
      "1586326711\n",
      "1550303102\n",
      "278283145\n",
      "1103905279\n",
      "2497529993\n",
      "993549511\n",
      "3538826777\n",
      "827898949\n",
      "1744767203\n",
      "1454149367\n",
      "347405931\n",
      "293704892\n",
      "739522939\n",
      "2787976300\n",
      "923371613\n",
      "3028338653\n",
      "1487664578\n",
      "1269177166\n",
      "1108403661\n",
      "2333147459\n",
      "3468047501\n",
      "3767013626\n",
      "3224645638\n",
      "216444033\n",
      "873431322\n",
      "2428674822\n",
      "205263707\n",
      "3132866966\n",
      "3313916789\n",
      "964022396\n",
      "3691436413\n",
      "768347323\n",
      "2334284253\n",
      "3571135595\n"
     ]
    }
   ],
   "source": [
    "## 64位， 40个repeat\n",
    "import numpy as np  \n",
    "import collections  \n",
    "from typing import Mapping  \n",
    "from sklearn.neighbors import NearestNeighbors  \n",
    "from scipy.spatial.distance import hamming  \n",
    "import mmh3  \n",
    "\n",
    "def _hash(kmer_index: int, seed: int) -> np.ndarray:  \n",
    "    hash_value = mmh3.hash(str(kmer_index), seed=seed)  \n",
    "    binary_string = \"{0:064b}\".format(hash_value & 0xFFFFFFFFFFFFFFFF)\n",
    "    hash_array = np.array([int(x) for x in binary_string], dtype=np.int32)  \n",
    "    return hash_array  \n",
    "\n",
    "def _get_simhash(  \n",
    "    read_features: list,  \n",
    "    feature_matrix: list,   \n",
    "    repeat: int,   \n",
    "    seed: int) -> Mapping[int,list]:  \n",
    "      \n",
    "    rng = np.random.default_rng(seed)  \n",
    "    hash_seeds = rng.integers(low=0, high=2**32 - 1, size=repeat, dtype=np.uint64)  \n",
    "  \n",
    "    repeat_all_read_hash = []  \n",
    "    for s in hash_seeds:  \n",
    "        print(s)\n",
    "        kmer_hash_indice = {}  \n",
    "        for kmer_index in range(feature_matrix.shape[1]):  \n",
    "            kmer_index_str = str(kmer_index)  \n",
    "            hash_list = _hash(kmer_index_str, seed=s)  \n",
    "            kmer_hash_indice[kmer_index] = hash_list  \n",
    "  \n",
    "        all_read_simhash = []  \n",
    "        for features in read_features.values():  \n",
    "            feature_count = dict(collections.Counter(features))  \n",
    "            one_read_hash = []  \n",
    "            for indice, count in feature_count.items():  \n",
    "                hash_list = kmer_hash_indice[indice]\n",
    "                hash_list = np.where(hash_list == 0, -1, hash_list) \n",
    "                weighted_hash_list = hash_list * count  \n",
    "                one_read_hash.append(weighted_hash_list)  \n",
    "            one_read_hash_array = np.array(one_read_hash)  \n",
    "            hash_sum = np.sum(one_read_hash_array, axis=0)   \n",
    "            simhash_value = np.where(hash_sum > 0, 1, 0)  \n",
    "            all_read_simhash.append(simhash_value)  \n",
    "  \n",
    "        repeat_all_read_hash.append(all_read_simhash)  \n",
    "  \n",
    "    concat_simhash = np.concatenate(repeat_all_read_hash, axis=1)  \n",
    "  \n",
    "    return concat_simhash \n",
    "\n",
    "concat_simhash = _get_simhash(read_features,feature_matrix,repeat = 40, seed = 4829)\n",
    "def hamming_distance(x, y):  \n",
    "    return np.count_nonzero(x != y)\n",
    "nbrs = NearestNeighbors(n_neighbors=21, algorithm='auto', metric=hamming_distance)\n",
    "nbrs.fit(concat_simhash)  \n",
    "indices = nbrs.kneighbors(concat_simhash,return_distance=False)\n",
    "nbr_indices = indices[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed)\n",
    "beta = rng.uniform(0, 1, (feature_count, dimension_count))\n",
    "x = rng.uniform(0, 1, (feature_count, dimension_count))\n",
    "u1 = rng.uniform(0, 1, (feature_count, dimension_count))\n",
    "u2 = rng.uniform(0, 1, (feature_count, dimension_count))\n",
    "\n",
    "for j_sample in range(0, sample_count):\n",
    "    feature_indices = sparse.find(data[:, j_sample] > 0)[0]\n",
    "    gamma = -np.log(np.multiply(u1[feature_indices, :], u2[feature_indices, :]))\n",
    "    t_matrix = np.floor(\n",
    "        np.divide(\n",
    "            matlib.repmat(\n",
    "                np.log(data[feature_indices, j_sample].todense()),\n",
    "                1,\n",
    "                dimension_count,\n",
    "            ),\n",
    "            gamma,\n",
    "        )\n",
    "        + beta[feature_indices, :]\n",
    "    )\n",
    "    y_matrix = np.exp(np.multiply(gamma, t_matrix - beta[feature_indices, :]))\n",
    "    a_matrix = np.divide(\n",
    "        -np.log(x[feature_indices, :]),\n",
    "        np.divide(y_matrix, u1[feature_indices, :]),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
