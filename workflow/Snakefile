REFERENCE_FASTA_PATH = dict(
    CHM13="/home/miaocj/docker_dir/data/human_ref/chm13v2.0.fa.gz",
    rice="/home/miaocj/docker_dir/kNN-overlap-finder/data/reference/rice/IRGSP.fasta.gz",
)
REGIONS = dict(
    CHM13=dict(
        TRA=("chr14", 14819498, 17749884),
        HLA=("chr6", 28476949, 34231258),
        IGK=("chr2", 87866370, 91790947),
        IGH=("chr14", 98839469, 101161492),
        chr8_centro_6M=("chr8", 42_000_000, 48_000_000),
        chr5_centro_9M=("chr5", 44_000_000, 53_000_000),
        chr6_50M=("chr6", 0, 50_000_000),
        chr5_100M=("chr5", 0, 100_000_000),
        chr1_248M=("chr1", 0, 1_000_000_000),
        chr22_51M=("chr22", 0, 100_000_000),
        chr9_150M=("chr9", 0, 1_000_000_000),
        chr13_113M=("chr13", 0, 1_000_000_000),
        chr14_101M=("chr14", 0, 1_000_000_000),
        chr15_98M=("chr15", 0, 1_000_000_000),
        chr21_45M=("chr21", 0, 1_000_000_000)
    ),
    ara=dict(
        chr1_30M=("1", 0, 100_000_000),
    ),
    rice=dict(
        chr1_43M=("chr01", 0, 100_000_000),
    ),
    yeast=dict(
        chr4_1M=("ref|NC_001136|", 0, 2_000_000),
    ),
    hg002=dict(
        HLA=("chr6_MATERNAL", 28476949, 34231258),
        IGK=("chr2_MATERNAL", 87866370, 91790947),
        chr1_248M=("chr1_MATERNAL", 0, 1_000_000_000),
    ),
)

wildcard_constraints:
    length_kb=r"\d+",
    sample=r"\w+",
    region=r"\w+",
    platform=r"\w+",
    encoding=r"\w+",

##For simulated, generating reads
rule extract_regional_reference:
    input:
        fasta=lambda wildcards: REFERENCE_FASTA_PATH[wildcards["sample"]],
    output:
        fasta="data/regional_reference/{sample}/{region}/reference.fasta.gz",
    params:
        region=lambda wildcards: REGIONS[wildcards["sample"]][wildcards["region"]],
    conda:
        "envs/default.yaml"
    script:
        "scripts/extract_regional_reference.smk.py"

# For real reads, get location on genome via minimap2.
# These reads have sampled to 30x depth.

rule map_real_reads_to_genome:
    input:
        reads="data/real_reads/{sample}/{platform}/all_reads.fq.gz",
        reference="data/reference/{sample}/reference.fasta",
    output:
        all_paf="data/real_reads/{sample}/{platform}/all_aligned.paf",
    conda:
        "envs/minimap2.yaml"
    threads: 128
    shell:
        """
        minimap2 -x map-ont {input.reference} {input.reads} --secondary=no --MD --eqx -I 10G -k 19 -w 5 -A 3 -B 2 -m 250 -t 60 > {output.all_paf}
        """

# rule filter_all_paf_loose:
#     input:
#         all_paf="data/real_reads/{sample}/{platform}/all_aligned.paf",
#     output:
#         mid_paf="data/real_reads/{sample}/{platform}/middle_aligned.paf",
#         filter_paf="data/real_reads/{sample}/{platform}/loose_filter_aligned.paf",
#     shell:
#         """
#         awk '($2 >= 5000) && ($12 >= 30)' {input.all_paf}> {output.mid_paf}
#         python workflow/scripts/save_max_match_base_for_paf.py {output.mid_paf} {output.filter_paf}
#         """

# rule extrace_fasta_from_paf_all_loose:
#     input:
#         filter_paf="data/real_reads/{sample}/{platform}/loose_filter_aligned.paf",
#         reads="data/real_reads/{sample}/{platform}/all_reads.fq.gz",
#     output:
#         filter_reads="data/regional_reads/{sample}/all/loose_filter_{platform}/reads.fasta.gz",
#     shell:
#         """
#         cut -f1 {input.filter_paf} |sort  |uniq | seqkit grep -f - {input.reads} | seqkit fq2fa - | gzip > {output.filter_reads}
#         """

rule filter_all_paf:
    input:
        all_paf="data/real_reads/{sample}/{platform}/all_aligned.paf",
    output:
        mid_paf="data/real_reads/{sample}/{platform}/middle_aligned.paf",
        filter_paf="data/real_reads/{sample}/{platform}/filter_aligned.paf",
    shell:
        """
        awk '($2 >= 5000) && ($10/$2 >= 0.5) && ($12 >= 30)' {input.all_paf}> {output.mid_paf}
        python workflow/scripts/save_max_match_base_for_paf.py {output.mid_paf} {output.filter_paf}
        """

rule extrace_fasta_from_paf_all:
    input:
        filter_paf="data/real_reads/{sample}/{platform}/filter_aligned.paf",
        reads="data/real_reads/{sample}/{platform}/all_reads.fq.gz",
    output:
        filter_reads="data/regional_reads/{sample}/all/filter3_{platform}/reads.fasta.gz",
    shell:
        """
        cut -f1 {input.filter_paf} |sort  |uniq | seqkit grep -f - {input.reads} | seqkit fq2fa - | gzip > {output.filter_reads}
        """

rule extrace_fasta_from_paf_regional:
    input:
        filter_paf="data/real_reads/{sample}/{platform}/filter_aligned.paf",
        reads="data/real_reads/{sample}/{platform}/all_reads.fq.gz",
    output:
        paf="data/regional_reads/{sample}/{region}/filter3_{platform}/filter_aligned.paf",
        filter_reads="data/regional_reads/{sample}/{region}/filter3_{platform}/reads.fasta.gz",
    params:
        chromosome=lambda wildcards: REGIONS[wildcards["sample"]][wildcards["region"]][0],
        start=lambda wildcards: REGIONS[wildcards["sample"]][wildcards["region"]][1],
        end=lambda wildcards: REGIONS[wildcards["sample"]][wildcards["region"]][2],
    wildcard_constraints:
        region=r'(HLA|IGK|chr22_51M|chr1_248M)'
    conda: "envs/default.yaml"
    shell:
        """
        awk '$6 == "{params.chromosome}" && $8 < {params.end} && $9 > {params.start}' {input.filter_paf} > {output.paf}
        cut -f1 {output.paf} |sort  |uniq | seqkit grep -f - {input.reads} | seqkit fq2fa - | gzip > {output.filter_reads}
        """

rule read_info_for_all:
    input:
        paf="data/real_reads/{sample}/{platform}/filter_aligned.paf",
    output:
        tsv="data/real_reads/{sample}/{platform}/filter_all_read_info.tsv.gz",
    script:
        "scripts/get_real_read_info_for_chrs1.smk.py"


rule get_metadata:
    input:
        fasta="data/regional_reads/{sample}/{region}/filter3_{platform}/reads.fasta.gz",
        tsv="data/real_reads/{sample}/{platform}/filter_all_read_info.tsv.gz",
    output:
        metadata="data/regional_reads/{sample}/{region}/filter3_{platform}/metadata.tsv.gz",
    wildcard_constraints:
        sample=r'(CHM13|rice|ara|droso|caenor)'
    conda:
        "envs/default.yaml"
    shell:
        """
        python /home/miaocj/docker_dir/kNN-overlap-finder/workflow/scripts/get_metadata.smk.py {input.fasta} {input.tsv} {output.metadata}
        """
## Encode reads. The reads.fasta include fasta belong to this reigion, so this script fits for simulate and real reads.
rule kmer_encoding:
    input:
        fasta="data/regional_reads/{sample}/{region}/{platform}/reads.fasta.gz",
    output:
        npz="data/feature_matrix/{sample}/{region}/{platform}/kmer_k{k}/feature_matrix.npz",
        json="data/feature_matrix/{sample}/{region}/{platform}/kmer_k{k}/read_features.json.gz",
    params:
        sample_fraction=0.1,
        min_multiplicity=2,
        seed=562104830,
    wildcard_constraints:
        k=r"\d+",
    conda:
        "envs/default.yaml"
    script:
        "scripts/kmer_encoding_for_sim.smk.py"

rule hash_kmer_encoding:
    input:
        fasta="data/regional_reads/{sample}/{region}/{platform}/reads.fasta.gz",
    output:
        npz="data/feature_matrix/{sample}/{region}/{platform}/hash_k{k}/feature_matrix.npz",
    params:
        sample_fraction=0.1,
        min_multiplicity=2,
        seed=562104830,
    wildcard_constraints:
        k=r"\d+",
    threads: 16
    conda:
        "envs/evaluate.yaml"
    script:
        "scripts/hash_kmer_encoding.smk.py"


rule minimizer_encoding:
    input:
        fasta="data/regional_reads/{sample}/{region}/{platform}/reads.fasta.gz",
    output:
        npz="data/feature_matrix/{sample}/{region}/{platform}/minimizer_k{k}_w{w}/feature_matrix.npz",
        json="data/feature_matrix/{sample}/{region}/{platform}/minimizer_k{k}_w{w}/read_features.json.gz",
    params:
        min_multiplicity=2, ## 区别于kmer编码，指的是包含某kmer数量的reads数目小于2
        seed=562104830,
    wildcard_constraints:
        k=r"\d+",
    conda:
        "envs/default.yaml"
    script:
        "scripts/minimizer_encoding.smk.py"


rule generate_reference_graph:
    input:
        metadata="data/regional_reads/{sample}/{region}/{platform}/metadata.tsv.gz",
    output:
        ref_graph="data/regional_reads/{sample}/{region}/{platform}/reference_graph.gpickle",
    wildcard_constraints:
        region=r'(HLA|IGK|chr22_51M|chr1_248M)',  # 排除"all"
        sample=r'(CHM13|rice|ara|caenor|droso)'
    conda:
        "envs/default.yaml"
    script:
        "scripts/generate_reference_graph.smk.py"

rule generate_reference_graph_for_chrs:
    input:
        metadata="data/regional_reads/{sample}/all/{platform}/metadata.tsv.gz",
    output:
        ref_graph="data/regional_reads/{sample}/all/{platform}/reference_graph.gpickle",
    threads: 1
    conda:
        "envs/default.yaml"
    script:
        "scripts/generate_reference_graph_for_chrs.smk.py"

#--------------------up for real data--------------------------------------------------------

rule run_minimap2_ava:
    input:
        fasta="data/regional_reads/{sample}/{region}/{platform}/reads.fasta.gz",
    output:
        paf_minimap2="data/minimap2/{sample}/{region}/{platform}/hash_k21/alignment.paf",
        minimap2_log="data/evaluation64/{sample}/{region}/{platform}/hash_k21/minimap2_time.log",
    params:
        preset="ava-ont",
    conda:
        "envs/minimap2.yaml"
    threads: 64
    shell:
        """
        /usr/bin/time -v -o {output.minimap2_log} \
        minimap2 -x {params.preset} -t {threads} {input.fasta} {input.fasta} > {output.paf_minimap2}
        """

rule run_daligner:
    input:
        fasta="data/regional_reads/{sample}/{region}/{platform}/reads.fasta.gz",
    output:
        maf="data/daligner/{sample}/{region}/{platform}/alignment.maf.gz",
    params:
        k = 16,
        average_correlation=".9",
        min_alignment_length=1000,
        min_alignment_score=50,
    threads: 8
    conda:
        "envs/daligner.yaml"
    shell: 
        """
        daligner \
            -k{params.k} \
            -e{params.average_correlation} \
            -l{params.min_alignment_length} \
            -s{params.min_alignment_score} \
            -T{threads} \
            -v \
            {input.fasta} {input.fasta} \
        | gzip -c > {output.maf}
        """

## specific parameters refer canu
rule run_mhap:
    input:
        fasta="data/regional_reads/{sample}/{region}/{platform}/reads.fasta.gz",
    output:
        txt=temp("data/MHAP/{sample}/{region}/{platform}/hash_k21/alignment.txt"),
        txt_gz="data/MHAP/{sample}/{region}/{platform}/hash_k21/alignment.txt.gz",
        log="data/evaluation64/{sample}/{region}/{platform}/hash_k21/MHAP_time.log",
    threads:64
    shell:
        """
        /usr/bin/time -v -o {output.log} \
        java  -Xms500g -XX:ParallelGCThreads={threads} -server -jar ~/docker_dir/biosoft/mhap-2.1.1.jar \
        -s {input.fasta}\
        --repeat-weight 0.9 --repeat-idf-scale 10 -k 16 \
        --store-full-id \
        --num-hashes 768 \
        --num-min-matches 20 \
        --threshold 0.73 \
        --filter-threshold 0.0000001 \
        --ordered-sketch-size 1536 \
        --ordered-kmer-size 12 \
        --min-olap-length 500 \
        --num-threads {threads} \
        > {output.txt}
        gzip -c {output.txt} > {output.txt_gz}
        """

rule run_xread:
    input:
        fasta="data/regional_reads/{sample}/{region}/{platform}/reads.fasta.gz",
    output:
        paf="data/xRead/{sample}/{region}/{platform}/hash_k21/alignment.paf",
        log="data/evaluation64/{sample}/{region}/{platform}/hash_k21/xRead_time.log",
    threads:64
    params:
        xread_params=lambda wildcards: 
        "-k 19 -w 40 -p 2 " if wildcards.platform == "filter3_real_pb" 
        else "-k 15 -w 5 -p 1", 
    shell:
        """
        /usr/bin/time -v -o {output.log} \
        ~/docker_dir/biosoft/xRead-v1.0.0/xRead {input.fasta} {params.xread_params} -b 30 -m 30 -n 20 -x 5.0 -t {threads} -M {threads} \
        > {output.paf}
        """
        ### -x 5.0 suitable for low depth data, -b -m -n set loose filter standard

rule run_mecat2:
    input:
        fasta="data/regional_reads/{sample}/{region}/{platform}/reads.fasta.gz",
    output:
        wd=directory("data/MECAT2/{sample}/{region}/{platform}/hash_k21"),
        txt=temp("data/MECAT2/{sample}/{region}/{platform}/hash_k21/alignment.txt"),
        txt_gz="data/MECAT2/{sample}/{region}/{platform}/hash_k21/alignment.txt.gz",
        log="data/evaluation64/{sample}/{region}/{platform}/hash_k21/MECAT2_time.log",
    threads:64
    shell:
        """
        gunzip -c {input.fasta} > {output.wd}/reads.fasta
        /usr/bin/time -v -o {output.log} \
        ~/docker_dir/biosoft/MECAT2/Linux-amd64/bin/mecat2pw \
        -d {output.wd}/reads.fasta -w {output.wd} -t {threads} -o {output.txt} -n 50 
        gzip -c {output.txt} > {output.txt_gz}
        rm {output.wd}/reads.fasta
        """

rule run_blend:
    input:
        fasta="data/regional_reads/{sample}/{region}/{platform}/reads.fasta.gz",
    output:
        paf="data/BLEND/{sample}/{region}/{platform}/hash_k21/alignment.paf",
        log="data/evaluation64/{sample}/{region}/{platform}/hash_k21/BLEND_time.log",
    conda:
        "envs/blend.yaml"
    params:
        blend_params=lambda wildcards: 
        "ava-hifi" if wildcards.platform == "filter3_real_pb" 
        else "ava-ont", 
    threads: 64
    shell:
        """
        /usr/bin/time -v -o {output.log} \
        blend -x {params.blend_params} {input.fasta} {input.fasta} -t {threads} > {output.paf}
        """

rule run_wtdbg2:
    input:
        fasta="data/regional_reads/{sample}/{region}/{platform}/reads.fasta.gz",
    output:
        paf="data/wtdbg2/{sample}/{region}/{platform}/hash_k21/alignment.txt.gz",
        log="data/evaluation64/{sample}/{region}/{platform}/hash_k21/wtdbg2_time.log",
    params:
        prefix = "data/wtdbg2/{sample}/{region}/{platform}/hash_k21/tmp",
        wtdbg2_params=lambda wildcards: 
        "-p 21 -k 0 -AS 4 -K 0.05 -s 0.5 -L 1000" if wildcards.platform == "filter3_real_pb" 
        else "-p 0 -k 15 -AS 2 -s 0.05", 
    threads: 64
    shell:
        """
        /usr/bin/time -v -o {output.log} \
        ~/docker_dir/biosoft/wtdbg2-2.5/wtdbg2 {params.wtdbg2_params} -t {threads} \
        -i {input.fasta} -o {params.prefix}
        mv {params.prefix}.alignments.gz  {output.paf}
        """

rule run_SeqNeighbor:
    input:
        fasta="data/regional_reads/{sample}/{region}/{platform}/reads.fasta.gz",
    output:
        folder=directory("data/FEDRANN/{sample}/{region}/{platform}/k21_s{kmer_sample}_d{embedding_dimension}/"),
        log="data/FEDRANN/{sample}/{region}/{platform}/k21_s{kmer_sample}_d{embedding_dimension}/FEDRANN_time.log",
    threads: 64
    params:
        image="seqneighbor:0.4.14.0",
        kmer_size=21,
        kmer_sample_fraction=lambda wildcards: 1/int(wildcards["kmer_sample"]),
        nndescent_n_trees=600,
    shell:
        """
        /usr/bin/time -v -o {output.log} \
        docker run \
            --rm \
            --name seqneighbor-$$ \
            -v /home/miaocj:/home/miaocj \
            -v "$(pwd)":/workdir -w /workdir \
            -e TZ=Asia/Shanghai \
            -e NUMBA_CACHE_DIR=/tmp/numba_cache \
            --user $(id -u):$(id -g) \
            --memory 800g \
            --shm-size 100g \
            {params.image} \
                -i {input.fasta} \
                -o {output.folder} \
                -k {params.kmer_size} \
                --kmer-sample-fraction {params.kmer_sample_fraction} \
                --seed 602 \
                --kmer-min-multiplicity 2 \
                --dimension-reduction mpsrp \
                --embedding-dimension {wildcards.embedding_dimension} \
                --nndescent-n-trees {params.nndescent_n_trees} \
                --threads {threads} 
        """

rule filter_paf:
    input:
        paf="data/{biosoft}/{sample}/{region}/{platform}/hash_k21/alignment.paf",
    output:
        filter_paf="data/{biosoft}/{sample}/{region}/{platform}/hash_k21/filter_alignment.paf",
    shell:
        """
        awk '$10 >= 100 && ($10/$11) >= 0.2' {input.paf} > {output.filter_paf}
        """
        
rule get_neighbors_paf:
    input:
        metadata="data/regional_reads/{sample}/{region}/{platform}/metadata.tsv.gz",
        paf="data/{biosoft}/{sample}/{region}/{platform}/{encoding}/filter_alignment.paf.gz",
    output:
        nbr_indice="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{biosoft}_nbr_matrix.npz",
        time="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{biosoft}_nn_time_tmp.json",
    threads: 1
    wildcard_constraints:
        method=r"[^/]+",
        biosoft=r'(minimap2|xRead|BLEND)',
    conda:
        "envs/evaluate.yaml"
    shell:
        """
        python workflow/scripts/get_neighbors.smk.py --input {input.metadata} {input.paf} \
        --output {output.nbr_indice} {output.time} --method {wildcards.biosoft} --threads {threads}
        """

rule get_neighbors_txt:
    input:
        metadata="data/regional_reads/{sample}/{region}/{platform}/metadata.tsv.gz",
        paf_minimap2="data/{biosoft}/{sample}/{region}/{platform}/{encoding}/alignment.txt.gz",
    output:
        nbr_indice="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{biosoft}_nbr_matrix.npz",
        time="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{biosoft}_nn_time_tmp.json",
    threads: 1
    wildcard_constraints:
        method=r"[^/]+",
        sample=r'(CHM13|rice|ara|droso|caenor)',
        biosoft=r'(wtdbg2|MECAT2|MHAP|FEDRANN)',
    conda:
        "envs/evaluate.yaml"
    shell:
        """
        python workflow/scripts/get_neighbors.smk.py --input {input.metadata} {input.paf_minimap2} \
        --output {output.nbr_indice} {output.time} --method {wildcards.biosoft} --threads {threads}
        """

rule get_neighbors:
    input:
        feature_matrix="data/feature_matrix/{sample}/{region}/{platform}/{encoding}/feature_matrix.npz",
        metadata="data/regional_reads/{sample}/{region}/{platform}/metadata.tsv.gz",
    output:
        nbr_indice="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{method}_nbr_matrix.npz",
        time="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{method}_nn_time.json",
        log="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{method}_time.log",
    threads: 64
    wildcard_constraints:
        sample=r'(CHM13|rice|ara|droso|caenor)',
        method=r'[A-Za-z]+_[A-Za-z]+_[A-Za-z]+_(\d+d_)?(IDF|TF|TF-IDF|None|binary|count)+',
    conda:
        "envs/evaluate.yaml"
    shell:
        """
        /usr/bin/time -v -o {output.log} \
        python workflow/scripts/get_neighbors.smk.py --input {input.metadata} {input.feature_matrix} \
        --output {output.nbr_indice} {output.time} --method {wildcards.method} --threads {threads}
        """

rule get_neighbors_params_tuning:
    input:
        feature_matrix="data/feature_matrix/{sample}/{region}/{platform}/{encoding}/feature_matrix.npz",
        metadata="data/regional_reads/{sample}/{region}/{platform}/metadata.tsv.gz",
        params="data/configs/{param_type}/{config}_parameter.json" 
    output:
        nbr_indice="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{param_type}_{config}/{method}_nbr_matrix.npz",
        time="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{param_type}_{config}/{method}_nn_time.json",
        log="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{param_type}_{config}/{method}_time.log",
    params:
        param_flag=lambda wc: "--ann-parameter" if wc.param_type == "ann" else "--dim-parameter"
    threads: 64 
    wildcard_constraints:
        evaluation_threads=r"[^/]+",
        method=r'[A-Za-z]+_[A-Za-z]+_[A-Za-z]+_(\d+d_)?(IDF|TF|TF-IDF|None|binary|count)+',
        param_type=r'ann|dim',
        sample=r'(CHM13|rice|ara|droso|caenor)',
    conda:
        "envs/evaluate.yaml"
    shell:
        """
        /usr/bin/time -v -o {output.log} \
        python workflow/scripts/get_neighbors.smk.py \
            --input {input.metadata} {input.feature_matrix}\
            --output {output.nbr_indice} {output.time} \
            --method {wildcards.method} \
            {params.param_flag} {input.params} \
            --threads {threads}
        """


rule get_neighbors_diff_n_neighbors:
    input:
        feature_matrix="data/feature_matrix/{sample}/{region}/{platform}/{encoding}/feature_matrix.npz",
        metadata="data/regional_reads/{sample}/{region}/{platform}/metadata.tsv.gz",
    output:
        nbr_indice="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{method}_n{n_neighbors}_nbr_matrix.npz",
        time="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{method}_n{n_neighbors}_nn_time.json",
        log="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{method}_n{n_neighbors}_time.log",
    threads: 64
    wildcard_constraints:
        method=r'[A-Za-z]+_[A-Za-z]+_[A-Za-z]+_(\d+d_)?(IDF|TF|TF-IDF|None|binary|count)+',
    conda:
        "envs/evaluate.yaml"
    shell:
        """
        /usr/bin/time -v -o {output.log} \
        python workflow/scripts/get_neighbors.smk.py --input {input.metadata} {input.feature_matrix} \
        --output {output.nbr_indice} {output.time} --method {wildcards.method} --n-neighbors {wildcards.n_neighbors} --threads {threads}
        """

rule evaluate_configs:
    input:
        metadata="data/regional_reads/{sample}/{region}/{platform}/metadata.tsv.gz",
        ref_graph="data/regional_reads/{sample}/{region}/{platform}/reference_graph.gpickle",
        nbr_indice="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{method}_nbr_matrix.npz",
    output:
        integral_stat="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{method}_full_stat.tsv",
    wildcard_constraints:
        method=r'[^/]+',
    conda:
        "envs/evaluate.yaml"
    script:
        "scripts/evaluate_neighbors.smk.py" 

rule evaluate_configs_partial:
    input:
        ref_graph="data/regional_reads/{sample}/{region}/{platform}/reference_graph.gpickle",
        nbr_indice="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{method}_nbr_matrix.npz",
    output:
        integral_stat="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{method}_part_stat.tsv",
        tp_counter="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{method}_tp_counter.pkl"
    wildcard_constraints:
        method=r'[^/]+',
    conda:
        "envs/evaluate.yaml"
    script:
        "scripts/evaluate_neighbors_easily.smk.py" 

use rule evaluate_configs as evaluate_configs_params_tuning with:
    input:
        metadata="data/regional_reads/{sample}/{region}/{platform}/metadata.tsv.gz",
        ref_graph="data/regional_reads/{sample}/{region}/{platform}/reference_graph.gpickle",
        nbr_indice="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{config}/{method}_nbr_matrix.npz",
    output:
        integral_stat="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{config}/{method}_full_stat.tsv",

use rule evaluate_configs_partial as evaluate_configs_partial_params_tuning with:
    input:
        ref_graph="data/regional_reads/{sample}/{region}/{platform}/reference_graph.gpickle",
        nbr_indice="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{config}/{method}_nbr_matrix.npz",
    output:
        integral_stat="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{config}/{method}_part_stat.tsv",
        tp_counter="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{config}/{method}_tp_counter.pkl"

rule get_stat:
    input:
        log="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{method}_time.log",
    output:
        time_stat="data/{evaluation_threads}/{sample}/{region}/{platform}/{encoding}/{method}_time_rss.tsv",
    shell:
        """
        python /home/miaocj/docker_dir/kNN-overlap-finder/workflow/scripts/generate_time_stat.py {input.log} {output.time_stat}
        """
        
rule get_neighbors_txt1:
    input:
        metadata="data/regional_reads/{sample}/{region}/{platform}/metadata.tsv.gz",
        paf_minimap2="data/FEDRANN/{sample}/{region}/{platform}/{encoding}/alignment_{suffix}.txt.gz",
    output:
        nbr_indice="data/evaluation64/{sample}/{region}/{platform}/{encoding}/FEDRANN_{suffix}_nbr_matrix.npz",
        time="data/evaluation64/{sample}/{region}/{platform}/{encoding}/FEDRANN_{suffix}_nn_time_tmp.json",
    threads: 1
    wildcard_constraints:
        sample=r'(CHM13|rice|ara|droso|caenor)',
    conda:
        "envs/evaluate.yaml"
    shell:
        """
        python workflow/scripts/get_neighbors.smk.py --input {input.metadata} {input.paf_minimap2} \
        --output {output.nbr_indice} {output.time} --method FEDRANN --threads {threads}
        """
# ----------------------------------------------------------------------------------------------------
rule tmp4:
    input:
        expand('data/evaluation64/{region}/hash_k21/{method}_full_stat.tsv',
        method=['SimHash_Hamming_None_IDF','Exact_Cosine_umap_1000d_IDF'],
        region=['CHM13/chr22_51M/filter3_real_wy','CHM13/chr22_51M/filter3_real_ONT_R10','CHM13/chr22_51M/filter3_real_pb'])
# rule wgs:
# 	input:
#         expand("data/evaluation64/CHM13/all/filter3_real_{platform}/hash_k21/{method}_full_stat.tsv",
#         platform=['wy','pb'],method=['minimap2','BLEND'])
rule generate_filter_reads:
    input:
        "data/regional_reads/CHM13/all/filter3_real_ONT_R10/reads.fasta.gz"

rule generate_filter_reads2:
    input:
        "data/regional_reads/droso/all/filter3_real_ONT/reads.fasta.gz"

rule encoding_first:
    input:
        expand("data/feature_matrix/{region}/hash_k21/feature_matrix.npz",
        region=["droso/all/filter3_real_ONT","ara/all/filter3_real_ONT2","caenor/all/filter3_real_ONT"])

rule encoding_first2:
    input:
        expand("data/evaluation64/{region}/hash_k21/ann_NNDescent_config3/NNDescent_Cosine_mpSRP_2000d_IDF_{target}",
        region=["droso/all/filter3_real_ONT","ara/all/filter3_real_ONT2","caenor/all/filter3_real_ONT"],
        target=['time_rss.tsv','full_stat.tsv'])

rule minimap2_for_all2:
    input:
        expand("data/minimap2/{region}/alignment.paf",
        region=['CHM13/all/filter3_real_ONT','CHM13/all/filter3_real_cyclone'])

rule minimap2_for_all:
    input:
        expand("data/evaluation64/{region}/kmer_k11/Minimap2_integral_stat.tsv",
        region=['CHM13/IGK/filter3_real_cyclone','CHM13/IGK/filter3_real_ONT','CHM13/IGK/filter3_real_pb',
        'CHM13/HLA/filter3_real_cyclone','CHM13/HLA/filter3_real_ONT','CHM13/HLA/filter3_real_pb',
        'ara/chr1_30M/filter3_real_ONT','rice/chr1_43M/filter3_real_ONT_new',
        'CHM13/chr22_51M/filter3_real_cyclone','CHM13/chr22_51M/filter3_real_ONT','CHM13/chr22_51M/filter3_real_pb',
        'CHM13/chr1_248M/filter3_real_cyclone','CHM13/chr1_248M/filter3_real_ONT','CHM13/chr1_248M/filter3_real_pb',
        'CHM13/all/filter3_real_cyclone','CHM13/all/filter3_real_ONT','CHM13/all/filter3_real_pb'])

rule test_biosoft:
    input:
        "data/xRead/ara/all/filter3_real_ONT/kmer_k21/filter_alignment.paf.gz",
        "data/minimap2/ara/all/filter3_real_ONT/kmer_k21/filter_alignment.paf.gz",
        "data/BLEND/ara/all/filter3_real_ONT/kmer_k21/filter_alignment.paf.gz",
        "data/MECAT2/ara/all/filter3_real_ONT/kmer_k21/alignment.txt.gz",
        "data/MHAP/ara/all/filter3_real_ONT/kmer_k21/alignment.txt.gz",
        "data/wtdbg2/ara/all/filter3_real_ONT/kmer_k21/alignment.txt.gz"

rule generate_graph:
    input:
        expand("data/regional_reads/CHM13/all/filter3_real_{platform}/reference_graph.gpickle",
        platform=['wy','pb','ONT_R10'])

rule test_biosoft2:
    input:
        expand("data/evaluation64/CHM13/all/{platform}/hash_k21/{biosoft}_{target}",
        platform=['filter3_real_wy'],
        biosoft=['BLEND','minimap2'],
        target=['time_rss.tsv','part_stat.tsv'])

rule test_biosoft3:
    input:
        expand("data/evaluation64/CHM13/all/filter3_real_{platform}/hash_k21/{biosoft}_{target}",
        platform=['pb','wy','ONT_R10'],
        biosoft=['xRead','BLEND','MECAT2','wtdbg2','minimap2'],
        target=['part_stat.tsv'])

rule test_biosoft_ont:
    input:
        expand("data/evaluation64/CHM13/all/{platform}/hash_k21/{biosoft}_{target}",
        platform=['filter3_real_ONT_R10'],
        biosoft=['xRead','minimap2','BLEND','wtdbg2'], #'MECAT2','MHAP'
        target=['time_rss.tsv','full_stat.tsv'])

rule test_biosoft_pb:
    input:
        expand("data/evaluation64/CHM13/all/{platform}/hash_k21/{biosoft}_{target}",
        platform=['filter3_real_pb'],
        biosoft=['xRead','minimap2','BLEND','wtdbg2','MECAT2'], #'MHAP',
        target=['time_rss.tsv','full_stat.tsv'])

rule simulate_chr1:
    input:
        expand("data/evaluation64/CHM13/chr1_248M/pbsim_ONT_95_20k_30dep/kmer_k11/{method}_integral_stat.tsv",
        method=['ann_NNDescent_config3/NNDescent_Cosine_SparseRP_3000d_IDF','Minimap2'])

rule rpf:
    input:
        expand("data/evaluation64/{region}/hash_k21/ann_RPForest_config1/RPForest_Cosine_SparseRP_1000d_IDF_full_stat.tsv",
        region=['CHM13/IGK/filter3_real_wy','CHM13/IGK/filter3_real_ONT_R10','CHM13/IGK/filter3_real_pb',
        'CHM13/HLA/filter3_real_wy','CHM13/HLA/filter3_real_ONT_R10','CHM13/HLA/filter3_real_pb',
        'droso/all/filter3_real_ONT','caenor/all/filter3_real_ONT'])

rule all_test0:
    input:
        expand('data/evaluation64/{region}/hash_k21/{method}_full_stat.tsv',
        method=['MHAP','minimap2','Exact_Cosine_None_IDF'],
        region=['CHM13/IGK/filter3_real_wy','CHM13/IGK/filter3_real_ONT_R10','CHM13/IGK/filter3_real_pb',
        'CHM13/HLA/filter3_real_wy','CHM13/HLA/filter3_real_ONT_R10','CHM13/HLA/filter3_real_pb',
        'CHM13/chr22_51M/filter3_real_wy','CHM13/chr22_51M/filter3_real_ONT_R10','CHM13/chr22_51M/filter3_real_pb',
        'droso/all/filter3_real_ONT','caenor/all/filter3_real_ONT'])

rule supple:
    input:
        expand("data/evaluation64/{region}/hash_k21/Exact_{distance}_None_{preprocess}_full_stat.tsv",
        region=['CHM13/IGK/filter3_real_wy','CHM13/IGK/filter3_real_ONT_R10','CHM13/IGK/filter3_real_pb',
        'CHM13/HLA/filter3_real_wy','CHM13/HLA/filter3_real_ONT_R10','CHM13/HLA/filter3_real_pb',
        'CHM13/chr22_51M/filter3_real_wy','CHM13/chr22_51M/filter3_real_ONT_R10','CHM13/chr22_51M/filter3_real_pb'],
        distance=['Cosine','Euclidean'],
        preprocess=['TF','IDF','TF-IDF','binary','count'])

rule all_test1:
    input:
        expand("data/evaluation64/{region}/filter3_real_{platform}/hash_k21/Exact_Cosine_{dim_method}_1000d_IDF_full_stat.tsv",
        region=['CHM13/IGK','CHM13/HLA'],
        platform=['wy','pb','ONT'],
        dim_method=['Spectural','GaussianRP','SparseRP','umap','PCA','scBiMap']), ## PCA scBimap 在wyHLA 无法运行成功
        expand("data/evaluation64/{region}/hash_k21/{method}_full_stat.tsv",
        region=['CHM13/IGK/filter3_real_wy','CHM13/IGK/filter3_real_ONT_R10','CHM13/IGK/filter3_real_pb',
        'CHM13/HLA/filter3_real_wy','CHM13/HLA/filter3_real_ONT_R10','CHM13/HLA/filter3_real_pb'],
        method=['SimHash_Hamming_None_IDF']),
        expand("data/evaluation64/{region}/hash_k21/Exact_{distance}_{dim_method}_1000d_IDF_full_stat.tsv",
        region=['CHM13/IGK/filter3_real_wy','CHM13/IGK/filter3_real_ONT_R10','CHM13/IGK/filter3_real_pb',
        'CHM13/HLA/filter3_real_wy','CHM13/HLA/filter3_real_ONT_R10','CHM13/HLA/filter3_real_pb',
        'CHM13/chr22_51M/filter3_real_wy','CHM13/chr22_51M/filter3_real_ONT_R10','CHM13/chr22_51M/filter3_real_pb'],
        distance=['Cosine','Euclidean'],dim_method=['GaussianRP','SparseRP'])  ##umap 在chr1 无法运行成功 降维花了7个小时  grp droso 运行超过7h
# rule dimension_method2:
#     input:
rule all_test2:
    input:
        expand("data/evaluation64/{region}/hash_k21/Exact_Cosine_SparseRP_{dim}d_IDF_full_stat.tsv",
        region=['CHM13/IGK/filter3_real_wy','CHM13/IGK/filter3_real_ONT_R10','CHM13/IGK/filter3_real_pb',
        'CHM13/HLA/filter3_real_wy','CHM13/HLA/filter3_real_ONT_R10','CHM13/HLA/filter3_real_pb',
        'CHM13/chr22_51M/filter3_real_wy','CHM13/chr22_51M/filter3_real_ONT_R10','CHM13/chr22_51M/filter3_real_pb'],
        dim=[100,300,500,1000,2000,3000]),
        # expand("data/evaluation64/{region}/hash_k21/Exact_Cosine_SparseRP_{dim}d_IDF_full_stat.tsv",
        # region=['droso/all/filter3_real_ONT','caenor/all/filter3_real_ONT'],
        # dim=[100,300,500,1000,2000,3000])

rule all_test3:
    input:
        expand("data/evaluation64/CHM13/chr1_248M/filter3_real_wy/kmer_k21/ann_NNDescent_{config}/NNDescent_Cosine_SparseRP_2000d_IDF_full_stat.tsv",
        config=['default','config1','config2','config3','config4','config5']),
        expand("data/evaluation64/CHM13/chr1_248M/filter3_real_wy/kmer_k21/ann_{config}/PQ_Cosine_SparseRP_2000d_IDF_integral_stat.tsv",
        config=['PQ_config1','PQ_config2','PQ_config5','PQ_default']),
        expand("data/evaluation64/CHM13/chr1_248M/filter3_real_wy/kmer_k21/ann_{config}/HNSW_Cosine_SparseRP_2000d_IDF_integral_stat.tsv",
        config=['HNSW_config1','HNSW_config2','HNSW_config3','HNSW_config4','HNSW_config5','HNSW_default']),
        expand("data/evaluation64/CHM13/chr1_248M/filter3_real_wy/kmer_k21/ann_{config}/IVFPQ_Cosine_SparseRP_2000d_IDF_integral_stat.tsv",
        config=['IVFPQ_config1','IVFPQ_config2','IVFPQ_config3','IVFPQ_config4','IVFPQ_config5','IVFPQ_default'])

##先测参数
rule ann_test7:
    input:
        expand("data/evaluation64/{region}/hash_k21/{method}_full_stat.tsv",
        method=['ann_NNDescent_config3/NNDescent_Cosine_SparseRP_1000d_IDF',
                'ann_HNSW_config1/HNSW_Cosine_SparseRP_1000d_IDF',
                'ann_PQ_config2/PQ_Cosine_SparseRP_1000d_IDF',
                'ann_IVFPQ_config5/IVFPQ_Cosine_SparseRP_1000d_IDF'],
        region=['CHM13/IGK/filter3_real_wy','CHM13/IGK/filter3_real_ONT_R10',
        'CHM13/HLA/filter3_real_wy','CHM13/HLA/filter3_real_ONT_R10',
        'CHM13/chr22_51M/filter3_real_wy','CHM13/chr22_51M/filter3_real_ONT_R10',
        'droso/all/filter3_real_ONT','caenor/all/filter3_real_ONT'])

rule test_k:
    input:
        expand("data/evaluation64/{region}/hash_k{k}/Exact_Cosine_None_TF-IDF_full_stat.tsv",
        region=['CHM13/IGK/filter3_real_wy','CHM13/IGK/filter3_real_ONT_R10',
        'CHM13/HLA/filter3_real_wy','CHM13/HLA/filter3_real_ONT_R10',
        'CHM13/chr22_51M/filter3_real_wy','CHM13/chr22_51M/filter3_real_ONT_R10'],
        k=[7,9,11,13,15,17,19,21,23])

rule ann_test8:
    input:
        expand("data/evaluation64/CHM13/chr1_248M/filter3_real_cyclone/kmer_k11/ann_NNDescent_config{config}/NNDescent_Cosine_SparseRP_3000d_IDF_integral_stat.tsv",
        config=[1,2,3,4,5,6,7,8])

rule ann_test9:
    input:
        expand("data/evaluation64/CHM13/chr1_248M/real_cyclone/kmer_k11/{config}_Cosine_SparseRP_3000d_IDF_integral_stat.tsv",
        config=['ann_RPForest_config1/RPForest','ann_RPForest_config2/RPForest'])


rule test_minimizer_small_region:
    input:
        expand("data/feature_matrix/CHM13/{region}/filter3_real_{platform}/{encode}/feature_matrix.npz",
        encode=['minimizer_k11_w10','minimizer_k11_w20','minimizer_k15_w10','kmer_k7','kmer_k9','kmer_k11','kmer_k15','kmer_k17','kmer_k19','kmer_k21','kmer_k23'],
        region=['HLA','IGK','chr22_51M'],
        platform=['cyclone','pb','ONT'])
rule test_all_encoding:
    input:
        expand("data/feature_matrix/CHM13/{region}/filter3_real_{platform}/{encode}/feature_matrix.npz",
        encode=['kmer_k15','kmer_k17','kmer_k19','kmer_k21'],
        region=['all'],
        platform=['cyclone'])

rule test_minimizer_small_region2:
    input:
        expand("data/evaluation64/CHM13/{region}/filter3_real_{platform}/{encode}/Exact_Cosine_None_TF-IDF_integral_stat.tsv",
        encode=['minimizer_k11_w10','minimizer_k11_w20','minimizer_k15_w10','kmer_k7','kmer_k9','kmer_k11','kmer_k15','kmer_k17','kmer_k19','kmer_k21','kmer_k23'],
        region=['HLA','IGK','chr22_51M'],
        platform=['cyclone','pb','ONT'])

rule test_minimizer_small_region1:
    input:
        expand("data/evaluation64/CHM13/{region}/filter3_real_cyclone/{encode}/Exact_Cosine_None_TF-IDF_integral_stat.tsv",
        encode=['minimizer_k11_w10','minimizer_k11_w20','minimizer_k15_w10'],
        region=['HLA','IGK','chr22_51M'])
#

rule test_encoding:
    input:
        expand("data/evaluation64/{region}/{encode}/Exact_Cosine_None_TF-IDF_integral_stat.tsv",
        region=['CHM13/IGK/real_cyclone','CHM13/HLA/real_cyclone',
        'CHM13/IGK/real_ONT','CHM13/HLA/real_ONT',
        'ara/chr1_30M/real_ONT','rice/chr1_43M/real_ONT_new',
        'CHM13/chr22_51M/real_cyclone','CHM13/chr22_51M/real_ONT',
        'CHM13/chr1_248M/real_cyclone','CHM13/chr1_248M/real_ONT'],
        encode=['minimizer_k11_w10','minimizer_k11_w20','minimizer_k11_w10','minimizer_k15_w10','kmer_k7','kmer_k9','kmer_k11','kmer_k15','kmer_k17'])



rule test_n1:
    input:
        expand("data/evaluation64/CHM13/chr1_248M/real_cyclone/kmer_k16/NNDescent_Cosine_SparseRP_3000d_IDF_n{n_neighbors}_nn_time.json",
        n_neighbors=[2,4,6,8,10,14,16])

rule chrs_test:
    input:
        expand("data/evaluation64/CHM13/{chromosome}/real_cyclone/kmer2_k11/NNDescent_Cosine_SparseRP_{dim}d_IDF_integral_stat.tsv",
        chromosome=['chr9_150M','chr13_113M','chr14_101M','chr15_98M','chr21_45M','chr22_51M','chr1_248M'],
        dim=[500,1000,2000,3000,6000])

rule small_region:
    input:
        expand("data/evaluation/{region}/kmer_k16/Exact_Cosine_{dim}_500d_IDF_overlap_stat.tsv",
        region=['CHM13/IGK/real_cyclone','CHM13/HLA/real_cyclone',
        'CHM13/IGK/real_ONT','CHM13/HLA/real_ONT','yeast/chr4_1M/real_cyclone'],
        dim=['Spectural','GaussianRP','SparseRP','umap','PCA','scBiMap'])

rule small_region_ANN:
    input:
        expand("data/evaluation64/{region}/kmer_k16/{ann}_Cosine_SparseRP_2000d_IDF_nn_time.json",
        region=['CHM13/IGK/real_cyclone','CHM13/HLA/real_cyclone',
        'CHM13/IGK/real_ONT','CHM13/HLA/real_ONT'],
        ann=['HNSW','PQ','IVFPQ','NNDescent'])
rule large_region_ANN:
    input:
        expand("data/evaluation64/{region}/kmer_k16/{ann}_Cosine_SparseRP_2000d_IDF_nn_time.json",
        region=['CHM13/IGK/real_cyclone','CHM13/HLA/real_cyclone',
        'CHM13/IGK/real_ONT','CHM13/HLA/real_ONT'],
        ann=['HNSW','PQ','IVFPQ','NNDescent'])


rule HLA_dim:
    input:
        expand("data/evaluation/CHM13/HLA/real_cyclone/kmer_k16/Exact_Cosine_SparseRP_{dim}d_IDF_overlap_stat.tsv",
        dim=[100,300,500,1000,2000,3000,6000])

rule chr22_dims:
    input:
        expand("data/evaluation/{region}/kmer_k16/Exact_{distance}_{dim_method}RP_500d_IDF_overlap_stat.tsv",
        region=['CHM13/HLA/real_cyclone','CHM13/IGK/real_cyclone','CHM13/chr22_51M/real_cyclone',
            'CHM13/HLA/real_ONT','CHM13/IGK/real_ONT','CHM13/chr22_51M/real_ONT',
            'ara/chr1_30M/real_ONT','rice/chr1_43M/real_ONT_new'],
        distance=['Cosine','Euclidean'],
        dim_method=['Gaussian','Sparse'])


rule middle_region_hash:
    input:
        expand("data/evaluation/{region}/kmer_k16/{method}_IDF_overlap_stat.tsv",
        region=['CHM13/IGK/real_cyclone','CHM13/HLA/real_cyclone',
        'CHM13/IGK/real_ONT','CHM13/HLA/real_ONT',
        'ara/chr1_30M/real_ONT','rice/chr1_43M/real_ONT_new',
        'CHM13/chr22_51M/real_cyclone','CHM13/chr22_51M/real_ONT'],
        method=['SimHash_Hamming_None','MinHash_Jaccard_None'])


rule middle_region:
    input:
        expand("data/evaluation/{region}/kmer_k16/Exact_Cosine_{dim}_500d_IDF_overlap_stat.tsv",
        region=['ara/chr1_30M/real_ONT','rice/chr1_43M/real_ONT_new',
        'CHM13/chr22_51M/real_cyclone','CHM13/chr22_51M/real_ONT'],
        dim=['GaussianRP','SparseRP','umap'])


rule middle_region_ANN:
    input:
        expand("data/evaluation64/{region}/kmer_k16/{ann}_Cosine_SparseRP_3000d_IDF_nn_time.json",
        region=['ara/chr1_30M/real_ONT','rice/chr1_43M/real_ONT_new',
        'CHM13/chr22_51M/real_cyclone','CHM13/chr22_51M/real_ONT'],
        ann=['HNSW','PQ','IVFPQ','NNDescent'])


rule large_region:
    input:
        expand("data/evaluation/{region}/kmer_k16/Exact_Cosine_SparseRP_3000d_IDF_overlap_stat.tsv",
        region=['CHM13/chr1_248M/real_cyclone','CHM13/chr1_248M/real_ONT'])

rule chr22_minimap2:
    input:
        expand("data/evaluation/{region}/kmer_k16/Minimap2_overlap_stat.tsv",
        region=['CHM13/chr22_51M/real_cyclone','CHM13/chr22_51M/real_ONT'])

rule minimap2:
    input:
        expand("data/evaluation/CHM13/{chromosome}/real_cyclone/kmer_k16/Minimap2_overlap_sizes.pkl",
        chromosome=['chr9_150M','chr13_113M','chr14_101M','chr15_98M','chr21_45M','chr22_51M'])

rule chr1_test:
    input:
        "data/evaluation/CHM13/chr1_248M/real_cyclone/kmer_k16/HNSW_Cosine_SparseRP_6000d_IDF_overlap_sizes.pkl"

rule simulate_data:
    input:
        expand("data/evaluation/{sample}/pbsim_ONT_{accuracy}_{length_kb}k_{depth}dep/kmer_k16/Exact_Cosine_None_{preprocess}_full_stat.tsv",
        sample=['CHM13/IGK','rice/chr1_43M'],
        accuracy=['99','97','95','93','91'],
        length_kb=[10,15,20,25,30],
        depth=[10,30,50],
        preprocess=['IDF'])

rule rpf_PT:
    input:
        expand("data/evaluation/CHM13/chr1_248M/real_cyclone/kmer_k16/RPForest_config{config}/RPForest_Cosine_SparseRP_3000d_IDF_overlap_sizes.pkl",
        config=[1,2,3])


rule minimap2_log:
    input:
        expand("data/minimap2/CHM13/{region}/real_ONT/minimap2.log",
        region=['chr1_248M']
        )

rule simulate:
    input:
        expand("data/evaluation/{region}/pbsim_ONT_{accu}_{length}k_{depth}dep/kmer2_k11/Exact_Cosine_None_{preprocess}_integral_stat.tsv",
        region=['CHM13/IGK','rice/chr1_43M'],
        accu=['99','97','95','93','91'],
        length=[10,15,20,25,30],
        depth=[10,30,50],
        preprocess=['TF-IDF']
        )



rule test_rpforest:
    input:
        expand("data/evaluation/CHM13/IGK/real_cyclone/kmer_k16/RPForest_config{num}_overlap_stat.tsv",
        num=['1','2','3','4','5','6','7','8','9','10'])


# rule simulate_perfect_sequencing_reads:
#     input:
#         fasta="data/regional_reference/{sample}/{region}/reference.fasta.gz",
#     output:
#         fasta="data/regional_reads/{sample}/{region}/perfect_{length_kb}k/reads.fasta.gz",
#     params:
#         length_kb=lambda wildcards: int(wildcards["length_kb"]),
#         depth=30,
#         seed=3558929,
#     wildcard_constraints:
#         length_kb=r"\d+",
#     conda:
#         "envs/default.yaml"
#     script:
#         "scripts/simulate_perfect_sequencing_reads.smk.py"


# rule run_pbsim3_ont:
#     input:
#         reference="data/regional_reference/{sample}/{region}/reference.fasta.gz",
#         model="resources/pbsim/ERRHMM-ONT-HQ.model",
#     output:
#         folder=directory(
#             "data/regional_reads/{sample}/{region}/pbsim_ONT_{accuracy}_{length_kb}k_{depth}dep"
#         ),
#         fasta="data/regional_reads/{sample}/{region}/pbsim_ONT_{accuracy}_{length_kb}k_{depth}dep/reads.fasta.gz",
#         maf="data/regional_reads/{sample}/{region}/pbsim_ONT_{accuracy}_{length_kb}k_{depth}dep/alignment.maf.gz",
#     wildcard_constraints:
#         accuracy=r"\d+",
#         length_kb=r"\d+",
#         depth=r"\d+",
#     params:
#         accuracy=lambda wildcards: float(wildcards["accuracy"]) / 100,
#         length_mean=lambda wildcards: int(wildcards["length_kb"]) * 1000,
#         length_sd=lambda wildcards: int(wildcards["length_kb"]) * 500,
#         length_min=1000,
#         seed=5023967,
#     conda:
#         "envs/pbsim.yaml"
#     shell:
#         """
#         gunzip -c {input.reference} \
#         | pbsim \
#             --strategy wgs \
#             --method errhmm \
#             --errhmm {input.model} \
#             --depth {wildcards.depth} \
#             --accuracy-mean {params.accuracy} \
#             --length-mean {params.length_mean} \
#             --length-sd  {params.length_sd} \
#             --length-min {params.length_min} \
#             --genome /dev/stdin \
#             --seed {params.seed} \
#             --prefix {output.folder}/output
#         sed -n '1~4s/^@/>/p;2~4p' {output.folder}/output_0001.fastq | gzip -c > {output.fasta}
#         gzip -c {output.folder}/output_0001.maf > {output.maf}
#         rm -rf {output.folder}/output*
#         """

# rule run_pbsim3_meta_ont:
#     input:
#         reference="data/metagenome_reference/GCR.fa.split/GCR.part_{num}.fa",
#         model="resources/pbsim/ERRHMM-ONT-HQ.model",
#     output:
#         folder=directory(
#             "data/metagenome_reads/part{num}/pbsim_ONT_{accuracy}_{length_kb}k"
#         ),
#         fasta="data/metagenome_reads/part{num}/pbsim_ONT_{accuracy}_{length_kb}k/reads.fasta.gz",
#         maf="data/metagenome_reads/part{num}/pbsim_ONT_{accuracy}_{length_kb}k/alignment.maf.gz",
#     wildcard_constraints:
#         accuracy=r"\d+",
#         length_kb=r"\d+",
#     params:
#         accuracy=lambda wildcards: float(wildcards["accuracy"]) / 100,
#         length_mean=lambda wildcards: int(wildcards["length_kb"]) * 1000,
#         length_sd=lambda wildcards: int(wildcards["length_kb"]) * 500,
#         length_min=10_000,
#         depth=10,
#         seed=5023967,
#     conda:
#         "envs/pbsim.yaml"
#     shell:
#         """
#         pbsim \
#             --strategy wgs \
#             --method errhmm \
#             --errhmm {input.model} \
#             --depth {params.depth} \
#             --accuracy-mean {params.accuracy} \
#             --length-mean {params.length_mean} \
#             --length-sd  {params.length_sd} \
#             --length-min {params.length_min} \
#             --genome {input.reference} \
#             --seed {params.seed} \
#             --prefix {output.folder}/output
#        """

# rule run_pbsim3_pb_hifi:
#     input:
#         reference="data/regional_reference/{sample}/{region}/reference.fasta.gz",
#         model="resources/pbsim/ERRHMM-SEQUEL.model",
#     output:
#         folder=directory(
#             "data/regional_reads/{sample}/{region}/pbsim_pb_hifi_{length_kb}k"
#         ),
#         fasta="data/regional_reads/{sample}/{region}/pbsim_pb_hifi_{length_kb}k/reads.fasta.gz",
#         maf="data/regional_reads/{sample}/{region}/pbsim_pb_hifi_{length_kb}k/alignment.maf.gz",
#     params:
#         length_mean=lambda wildcards: int(wildcards["length_kb"]) * 1000,
#         pass_num=10,
#         depth=20,
#         seed=5023967,
#     conda:
#         "envs/pbsim.yaml"
#     shell:
#         """
#         gunzip -c {input.reference} \
#         | pbsim \
#             --strategy wgs \
#             --method errhmm \
#             --errhmm {input.model} \
#             --depth {params.depth} \
#             --length-mean {params.length_mean} \
#             --pass-num {params.pass_num} \
#             --genome /dev/stdin \
#             --seed {params.seed} \
#             --prefix {output.folder}/output
#         samtools sort -@ 10  {output.folder}/output_0001.sam -o  {output.folder}/output_0001.bam
#         ccs  -j 10 {output.folder}/output_0001.bam  {output.folder}/output_hifi.fastq.gz
#         gunzip -c {output.folder}/output_hifi.fastq.gz | sed -n '1~4s/^@/>/p;2~4p' | gzip -c > {output.fasta}
#         gzip -c {output.folder}/output_0001.maf > {output.maf}
#         rm -rf {output.folder}/output*
#         """

# ###Get reads' location on the genome, save in read_info file.
# rule get_perfect_read_info:
#     input:
#         fasta="data/regional_reads/{sample}/{region}/{platform}/reads.fasta.gz",
#     output:
#         tsv="data/regional_reads/{sample}/{region}/{platform}/read_info.tsv.gz",
#     wildcard_constraints:
#         platform=r"perfect_.+",
#     conda:
#         "envs/default.yaml"
#     script:
#         "scripts/get_perfect_read_info.smk.py"


# rule get_pbsim_ONT_metadata:
#     input:
#         maf="data/regional_reads/{sample}/{region}/{platform}/alignment.maf.gz",
#     output:
#         tsv="data/regional_reads/{sample}/{region}/{platform}/read_info.tsv.gz",
#     wildcard_constraints:
#         platform=r"pbsim_ONT.+",
#     conda:
#         "envs/default.yaml"
#     script:
#         "scripts/get_pbsim_read_info_ont.smk.py"

# rule get_pbsim_pb_ccs_metadata:
#     input:
#         maf="data/regional_reads/{sample}/{region}/{platform}/alignment.maf.gz",
#         fasta="data/regional_reads/{sample}/{region}/{platform}/reads.fasta.gz",
#     output:
#         tsv="data/regional_reads/{sample}/{region}/{platform}/read_info.tsv.gz",
#     wildcard_constraints:
#         platform=r"pbsim_pb.+",
#     conda:
#         "envs/default.yaml"
#     script:
#         "scripts/get_pbsim_read_info_hifi.smk.py"

# rule get_neighbors_meta:
#     input:
#         ref_tax="data/feature_matrix/metagenome/{data_type}/{platform}/{encoding}/ref_read_tax.json.gz",
#         que_tax="data/feature_matrix/metagenome/{data_type}/{platform}/{encoding}/que_read_tax.json.gz",
#         ref_feature_matrix="data/feature_matrix/metagenome/{data_type}/{platform}/{encoding}/ref_feature_matrix.npz",
#         que_feature_matrix="data/feature_matrix/metagenome/{data_type}/{platform}/{encoding}/que_feature_matrix.npz",
#     output:
#         nbr_indice="data/evaluation/metagenome/{data_type}/{platform}/{encoding}/{method}_nbr_matrix.npz",
#         stat="data/evaluation/metagenome/{data_type}/{platform}/{encoding}/{method}_stat.tsv",
#         time="data/evaluation/metagenome/{data_type}/{platform}/{encoding}/{method}_nn_time.json"
#     threads: 8
#     benchmark:
#         "data/evaluation/metagenome/{data_type}/{platform}/{encoding}/{method}_benchmark.csv"
#     conda:
#         "envs/evaluate.yaml"
#     script:
#         "scripts/metagenome_kNN.smk.py"



# rule get_all_reads_info:
#     input:
#         fasta_aligned="data/regional_reads/{sample}/all/{platform}/aligned_read.fa.gz",
#         all_paf="data/real_reads/{sample}/{platform}/all_aligned.paf",
#     output:
#         tsv="data/regional_reads/{sample}/{region}/{platform}/read_info.tsv.gz",
#         stat="data/regional_reads/{sample}/{region}/{platform}/read_usage_statistic.tsv.gz",
#         fasta="data/regional_reads/{sample}/{region}/{platform}/reads.fasta.gz",
#     wildcard_constraints:
#         region=r"^(?!all$).*$",
#     conda:
#         "envs/default.yaml"
#     script:
#         "scripts/get_real_read_info.smk.py"
        
# ## Filter reads and save filtered reads in fasta file, finding reads' real location in genome and save it in tsv file.
# rule paf_to_read_info:
#     input:
#         fasta_aligned="data/regional_reads/{sample}/{region}/{platform}/aligned_read.fa.gz",
#         paf="data/regional_reads/{sample}/{region}/{platform}/alignment.paf",
#     output:
#         tsv="data/regional_reads/{sample}/{region}/{platform}/read_info.tsv.gz",
#         stat="data/regional_reads/{sample}/{region}/{platform}/read_usage_statistic.tsv.gz",
#         fasta="data/regional_reads/{sample}/{region}/{platform}/reads.fasta.gz",
#     wildcard_constraints:
#         region=r"^(?!all$).*$",
#     conda:
#         "envs/default.yaml"
#     script:
#         "scripts/get_real_read_info.smk.py"

# rule paf_to_read_info_for_chrs:
#     input:
#         fasta_aligned="data/regional_reads/{sample}/all/{platform}/aligned_read.fa.gz",
#         paf="data/real_reads/{sample}/{platform}/all_aligned.paf",
#     output:
#         tsv="data/regional_reads/{sample}/all/{platform}/read_info.tsv.gz",
#         fasta="data/regional_reads/{sample}/all/{platform}/reads.fasta",
#     conda:
#         "envs/default.yaml"
#     script:
#         "scripts/get_real_read_info_for_chrs.smk.py"

# rule filter_by_length_and_mapping_quality:
#     input:
#         tsv="data/regional_reads/{sample}/{region}/{platform}/read_info.tsv.gz",
#         fasta="data/regional_reads/{sample}/{region}/{platform}/reads.fasta.gz",
#         paf="data/real_reads/{sample}/{platform}/all_aligned.paf",
#     output:
#         tsv_out="data/regional_reads/{sample}/{region}/filter2_{platform}/read_info.tsv.gz",
#         read_name1="data/regional_reads/{sample}/{region}/filter2_{platform}/read_name1.txt",
#         read_name2="data/regional_reads/{sample}/{region}/filter2_{platform}/read_name2.txt",
#         read_name="data/regional_reads/{sample}/{region}/filter2_{platform}/read_name.txt",
#         fasta_out="data/regional_reads/{sample}/{region}/filter2_{platform}/reads.fasta.gz",
#     conda:
#         "envs/default.yaml"
#     shell:
#         """
#         python workflow/scripts/filter_by_length.py {input.tsv} {output.tsv_out} {output.read_name1}
#         awk '$12 >= 30 {{print $1}}' {input.paf} | sort -u > {output.read_name2}   
#         comm -12 {output.read_name1} {output.read_name2} > {output.read_name}   
#         seqkit grep -f {output.read_name} {input.fasta} -o {output.fasta_out}
#         """

# rule filter_by_length:
#     input:
#         tsv="data/regional_reads/{sample}/{region}/{platform}/read_info.tsv.gz",
#         fasta="data/regional_reads/{sample}/{region}/{platform}/reads.fasta.gz",
#     output:
#         tsv_out="data/regional_reads/{sample}/{region}/filter_{platform}/read_info.tsv.gz",
#         read_name="data/regional_reads/{sample}/{region}/filter_{platform}/read_name.txt",
#         fasta_out="data/regional_reads/{sample}/{region}/filter_{platform}/reads.fasta.gz",
#     conda:
#         "envs/default.yaml"
#     shell:
#         """
#         python workflow/scripts/filter_by_length.py {input.tsv} {output.tsv_out} {output.read_name}
#         seqkit grep -f {output.read_name} {input.fasta} -o {output.fasta_out}
#         """
# rule gzip:
#     input:
#         fasta="data/regional_reads/{sample}/all/{platform}/reads.fasta",
#     output:
#         fasta_gzip="data/regional_reads/{sample}/all/{platform}/reads.fasta.gz",
#     shell:
#         """
#         gzip {input.fasta} > {output.fasta_gzip}
#         """
